10/22 12:30:18 AM | 
10/22 12:30:18 AM | Parameters:
10/22 12:30:18 AM | ALPHA_LR=0.0006
10/22 12:30:18 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:30:18 AM | AUX_WEIGHT=0.4
10/22 12:30:18 AM | BATCH_SIZE=128
10/22 12:30:18 AM | CELLS_NUM=3
10/22 12:30:18 AM | CLEAN_ARCH=False
10/22 12:30:18 AM | CUTOUT_LENGTH=16
10/22 12:30:18 AM | DATA_DIR=/data/cifar
10/22 12:30:18 AM | DATA_PATH=./data/
10/22 12:30:18 AM | DATASET=imagenet
10/22 12:30:18 AM | DIST_URL=tcp://127.0.0.1:23456
10/22 12:30:18 AM | DISTRIBUTED=False
10/22 12:30:18 AM | DROP_PATH_PROB=0.2
10/22 12:30:18 AM | ENSEMBLE=False
10/22 12:30:18 AM | GPUS=[0]
10/22 12:30:18 AM | INIT_CHANNELS=16
10/22 12:30:18 AM | INPUT_CHANNELS=3
10/22 12:30:18 AM | LAYER_NUM=3
10/22 12:30:18 AM | LOCAL_RANK=0
10/22 12:30:18 AM | LR_RATIO=0.5
10/22 12:30:18 AM | MODEL_TYPE=cifar
10/22 12:30:18 AM | N_CLASSES=10
10/22 12:30:18 AM | NAME=cifar10-search
10/22 12:30:18 AM | NO_REPEAT=False
10/22 12:30:18 AM | PATH=searchs/cifar10-search
10/22 12:30:18 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:30:18 AM | PRETRAIN_DECAY=5
10/22 12:30:18 AM | PRETRAIN_EPOCHS=5
10/22 12:30:18 AM | PRINT_FREQ=50
10/22 12:30:18 AM | RETRAIN_EPOCHS=25
10/22 12:30:18 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:30:18 AM | RETRAIN_SETTING=0
10/22 12:30:18 AM | RETRAIN_UPDATE_W=False
10/22 12:30:18 AM | SAME_STRUCTURE=False
10/22 12:30:18 AM | SAMPLE_RATIO=0.2
10/22 12:30:18 AM | SEARCH_ITER=5
10/22 12:30:18 AM | SEARCH_ITER_EPOCHS=5
10/22 12:30:18 AM | SEED=0
10/22 12:30:18 AM | SHORT_CONNECT=False
10/22 12:30:18 AM | SYNC_PARAM=False
10/22 12:30:18 AM | TEACHER2STUDENT=False
10/22 12:30:18 AM | TEST_DIR=/data/imagenet/val
10/22 12:30:18 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:30:18 AM | TRAIN_PORTION=0.5
10/22 12:30:18 AM | UNROLLED=False
10/22 12:30:18 AM | USE_BETA=False
10/22 12:30:18 AM | VAL_DIR=/data/imagenet/train
10/22 12:30:18 AM | W_GRAD_CLIP=5.0
10/22 12:30:18 AM | W_LR=0.05
10/22 12:30:18 AM | W_LR_MIN=0.001
10/22 12:30:18 AM | W_MOMENTUM=0.9
10/22 12:30:18 AM | W_WEIGHT_DECAY=0.0003
10/22 12:30:18 AM | WORKERS=4
10/22 12:30:18 AM | WORLD_SIZE=1
10/22 12:30:18 AM | 
10/22 12:30:18 AM | Logger is set - training start
10/22 12:31:35 AM | 
10/22 12:31:35 AM | Parameters:
10/22 12:31:35 AM | ALPHA_LR=0.0003
10/22 12:31:35 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:31:35 AM | AUX_WEIGHT=0.4
10/22 12:31:35 AM | BATCH_SIZE=64
10/22 12:31:35 AM | CELLS_NUM=3
10/22 12:31:35 AM | CLEAN_ARCH=True
10/22 12:31:35 AM | CUTOUT_LENGTH=16
10/22 12:31:35 AM | DATA_DIR=/data/cifar
10/22 12:31:35 AM | DATA_PATH=./data/
10/22 12:31:35 AM | DATASET=cifar10
10/22 12:31:35 AM | DIST_URL='tcp://127.0.0.1:23343'
10/22 12:31:35 AM | DISTRIBUTED=True
10/22 12:31:35 AM | DROP_PATH_PROB=0.2
10/22 12:31:35 AM | ENSEMBLE=True
10/22 12:31:35 AM | GPUS=[0]
10/22 12:31:35 AM | INIT_CHANNELS=16
10/22 12:31:35 AM | INPUT_CHANNELS=3
10/22 12:31:35 AM | LAYER_NUM=3
10/22 12:31:35 AM | LOCAL_RANK=0
10/22 12:31:35 AM | LR_RATIO=0.5
10/22 12:31:35 AM | MODEL_TYPE=cifar
10/22 12:31:35 AM | N_CLASSES=10
10/22 12:31:35 AM | NAME=cifar10-search
10/22 12:31:35 AM | NO_REPEAT=False
10/22 12:31:35 AM | PATH=searchs/cifar10-search
10/22 12:31:35 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:31:35 AM | PRETRAIN_DECAY=0
10/22 12:31:35 AM | PRETRAIN_EPOCHS=0
10/22 12:31:35 AM | PRINT_FREQ=10
10/22 12:31:35 AM | RETRAIN_EPOCHS=1
10/22 12:31:35 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:31:35 AM | RETRAIN_SETTING=0
10/22 12:31:35 AM | RETRAIN_UPDATE_W=True
10/22 12:31:35 AM | SAME_STRUCTURE=True
10/22 12:31:35 AM | SAMPLE_RATIO=0.2
10/22 12:31:35 AM | SEARCH_ITER=25
10/22 12:31:35 AM | SEARCH_ITER_EPOCHS=1
10/22 12:31:35 AM | SEED=0
10/22 12:31:35 AM | SHORT_CONNECT=False
10/22 12:31:35 AM | SYNC_PARAM=True
10/22 12:31:35 AM | TEACHER2STUDENT=True
10/22 12:31:35 AM | TEST_DIR=/data/imagenet/val
10/22 12:31:35 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:31:35 AM | TRAIN_PORTION=0.5
10/22 12:31:35 AM | UNROLLED=False
10/22 12:31:35 AM | USE_BETA=True
10/22 12:31:35 AM | VAL_DIR=/data/imagenet/train
10/22 12:31:35 AM | W_GRAD_CLIP=5.0
10/22 12:31:35 AM | W_LR=0.05
10/22 12:31:35 AM | W_LR_MIN=0.001
10/22 12:31:35 AM | W_MOMENTUM=0.9
10/22 12:31:35 AM | W_WEIGHT_DECAY=0.0003
10/22 12:31:35 AM | WORKERS=1
10/22 12:31:35 AM | WORLD_SIZE=2
10/22 12:31:35 AM | 
10/22 12:31:35 AM | Logger is set - training start
10/22 12:31:48 AM | 
10/22 12:31:48 AM | Parameters:
10/22 12:31:48 AM | ALPHA_LR=0.0003
10/22 12:31:48 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:31:48 AM | AUX_WEIGHT=0.4
10/22 12:31:48 AM | BATCH_SIZE=64
10/22 12:31:48 AM | CELLS_NUM=3
10/22 12:31:48 AM | CLEAN_ARCH=True
10/22 12:31:48 AM | CUTOUT_LENGTH=16
10/22 12:31:48 AM | DATA_DIR=/data/cifar
10/22 12:31:48 AM | DATA_PATH=./data/
10/22 12:31:48 AM | DATASET=cifar10
10/22 12:31:48 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 12:31:48 AM | DISTRIBUTED=True
10/22 12:31:48 AM | DROP_PATH_PROB=0.2
10/22 12:31:48 AM | ENSEMBLE=True
10/22 12:31:48 AM | GPUS=[0]
10/22 12:31:48 AM | INIT_CHANNELS=16
10/22 12:31:48 AM | INPUT_CHANNELS=3
10/22 12:31:48 AM | LAYER_NUM=3
10/22 12:31:48 AM | LOCAL_RANK=0
10/22 12:31:48 AM | LR_RATIO=0.5
10/22 12:31:48 AM | MODEL_TYPE=cifar
10/22 12:31:48 AM | N_CLASSES=10
10/22 12:31:48 AM | NAME=cifar10-search
10/22 12:31:48 AM | NO_REPEAT=False
10/22 12:31:48 AM | PATH=searchs/cifar10-search
10/22 12:31:48 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:31:48 AM | PRETRAIN_DECAY=0
10/22 12:31:48 AM | PRETRAIN_EPOCHS=0
10/22 12:31:48 AM | PRINT_FREQ=10
10/22 12:31:48 AM | RETRAIN_EPOCHS=1
10/22 12:31:48 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:31:48 AM | RETRAIN_SETTING=0
10/22 12:31:48 AM | RETRAIN_UPDATE_W=True
10/22 12:31:48 AM | SAME_STRUCTURE=True
10/22 12:31:48 AM | SAMPLE_RATIO=0.2
10/22 12:31:48 AM | SEARCH_ITER=25
10/22 12:31:48 AM | SEARCH_ITER_EPOCHS=1
10/22 12:31:48 AM | SEED=0
10/22 12:31:48 AM | SHORT_CONNECT=False
10/22 12:31:48 AM | SYNC_PARAM=True
10/22 12:31:48 AM | TEACHER2STUDENT=True
10/22 12:31:48 AM | TEST_DIR=/data/imagenet/val
10/22 12:31:48 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:31:48 AM | TRAIN_PORTION=0.5
10/22 12:31:48 AM | UNROLLED=False
10/22 12:31:48 AM | USE_BETA=True
10/22 12:31:48 AM | VAL_DIR=/data/imagenet/train
10/22 12:31:48 AM | W_GRAD_CLIP=5.0
10/22 12:31:48 AM | W_LR=0.05
10/22 12:31:48 AM | W_LR_MIN=0.001
10/22 12:31:48 AM | W_MOMENTUM=0.9
10/22 12:31:48 AM | W_WEIGHT_DECAY=0.0003
10/22 12:31:48 AM | WORKERS=1
10/22 12:31:48 AM | WORLD_SIZE=2
10/22 12:31:48 AM | 
10/22 12:31:48 AM | Logger is set - training start
10/22 12:32:09 AM | 
10/22 12:32:09 AM | Parameters:
10/22 12:32:09 AM | ALPHA_LR=0.0003
10/22 12:32:09 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:32:09 AM | AUX_WEIGHT=0.4
10/22 12:32:09 AM | BATCH_SIZE=64
10/22 12:32:09 AM | CELLS_NUM=3
10/22 12:32:09 AM | CLEAN_ARCH=True
10/22 12:32:09 AM | CUTOUT_LENGTH=16
10/22 12:32:09 AM | DATA_DIR=/data/cifar
10/22 12:32:09 AM | DATA_PATH=./data/
10/22 12:32:09 AM | DATASET=cifar10
10/22 12:32:09 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 12:32:09 AM | DISTRIBUTED=True
10/22 12:32:09 AM | DROP_PATH_PROB=0.2
10/22 12:32:09 AM | ENSEMBLE=True
10/22 12:32:09 AM | GPUS=[0]
10/22 12:32:09 AM | INIT_CHANNELS=16
10/22 12:32:09 AM | INPUT_CHANNELS=3
10/22 12:32:09 AM | LAYER_NUM=3
10/22 12:32:09 AM | LOCAL_RANK=0
10/22 12:32:09 AM | LR_RATIO=0.5
10/22 12:32:09 AM | MODEL_TYPE=cifar
10/22 12:32:09 AM | N_CLASSES=10
10/22 12:32:09 AM | NAME=cifar10-search
10/22 12:32:09 AM | NO_REPEAT=False
10/22 12:32:09 AM | PATH=searchs/cifar10-search
10/22 12:32:09 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:32:09 AM | PRETRAIN_DECAY=0
10/22 12:32:09 AM | PRETRAIN_EPOCHS=0
10/22 12:32:09 AM | PRINT_FREQ=10
10/22 12:32:09 AM | RETRAIN_EPOCHS=1
10/22 12:32:09 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:32:09 AM | RETRAIN_SETTING=0
10/22 12:32:09 AM | RETRAIN_UPDATE_W=True
10/22 12:32:09 AM | SAME_STRUCTURE=True
10/22 12:32:09 AM | SAMPLE_RATIO=0.2
10/22 12:32:09 AM | SEARCH_ITER=25
10/22 12:32:09 AM | SEARCH_ITER_EPOCHS=1
10/22 12:32:09 AM | SEED=0
10/22 12:32:09 AM | SHORT_CONNECT=False
10/22 12:32:09 AM | SYNC_PARAM=True
10/22 12:32:09 AM | TEACHER2STUDENT=True
10/22 12:32:09 AM | TEST_DIR=/data/imagenet/val
10/22 12:32:09 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:32:09 AM | TRAIN_PORTION=0.5
10/22 12:32:09 AM | UNROLLED=False
10/22 12:32:09 AM | USE_BETA=True
10/22 12:32:09 AM | VAL_DIR=/data/imagenet/train
10/22 12:32:09 AM | W_GRAD_CLIP=5.0
10/22 12:32:09 AM | W_LR=0.05
10/22 12:32:09 AM | W_LR_MIN=0.001
10/22 12:32:09 AM | W_MOMENTUM=0.9
10/22 12:32:09 AM | W_WEIGHT_DECAY=0.0003
10/22 12:32:09 AM | WORKERS=1
10/22 12:32:09 AM | WORLD_SIZE=2
10/22 12:32:09 AM | 
10/22 12:32:09 AM | Logger is set - training start
10/22 12:32:53 AM | 
10/22 12:32:53 AM | Parameters:
10/22 12:32:53 AM | ALPHA_LR=0.0003
10/22 12:32:53 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:32:53 AM | AUX_WEIGHT=0.4
10/22 12:32:53 AM | BATCH_SIZE=64
10/22 12:32:53 AM | CELLS_NUM=3
10/22 12:32:53 AM | CLEAN_ARCH=True
10/22 12:32:53 AM | CUTOUT_LENGTH=16
10/22 12:32:53 AM | DATA_DIR=./cifar
10/22 12:32:53 AM | DATA_PATH=./data/
10/22 12:32:53 AM | DATASET=cifar10
10/22 12:32:53 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 12:32:53 AM | DISTRIBUTED=True
10/22 12:32:53 AM | DROP_PATH_PROB=0.2
10/22 12:32:53 AM | ENSEMBLE=True
10/22 12:32:53 AM | GPUS=[0]
10/22 12:32:53 AM | INIT_CHANNELS=16
10/22 12:32:53 AM | INPUT_CHANNELS=3
10/22 12:32:53 AM | LAYER_NUM=3
10/22 12:32:53 AM | LOCAL_RANK=0
10/22 12:32:53 AM | LR_RATIO=0.5
10/22 12:32:53 AM | MODEL_TYPE=cifar
10/22 12:32:53 AM | N_CLASSES=10
10/22 12:32:53 AM | NAME=cifar10-search
10/22 12:32:53 AM | NO_REPEAT=False
10/22 12:32:53 AM | PATH=searchs/cifar10-search
10/22 12:32:53 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:32:53 AM | PRETRAIN_DECAY=0
10/22 12:32:53 AM | PRETRAIN_EPOCHS=0
10/22 12:32:53 AM | PRINT_FREQ=10
10/22 12:32:53 AM | RETRAIN_EPOCHS=1
10/22 12:32:53 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:32:53 AM | RETRAIN_SETTING=0
10/22 12:32:53 AM | RETRAIN_UPDATE_W=True
10/22 12:32:53 AM | SAME_STRUCTURE=True
10/22 12:32:53 AM | SAMPLE_RATIO=0.2
10/22 12:32:53 AM | SEARCH_ITER=25
10/22 12:32:53 AM | SEARCH_ITER_EPOCHS=1
10/22 12:32:53 AM | SEED=0
10/22 12:32:53 AM | SHORT_CONNECT=False
10/22 12:32:53 AM | SYNC_PARAM=True
10/22 12:32:53 AM | TEACHER2STUDENT=True
10/22 12:32:53 AM | TEST_DIR=/data/imagenet/val
10/22 12:32:53 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:32:53 AM | TRAIN_PORTION=0.5
10/22 12:32:53 AM | UNROLLED=False
10/22 12:32:53 AM | USE_BETA=True
10/22 12:32:53 AM | VAL_DIR=/data/imagenet/train
10/22 12:32:53 AM | W_GRAD_CLIP=5.0
10/22 12:32:53 AM | W_LR=0.05
10/22 12:32:53 AM | W_LR_MIN=0.001
10/22 12:32:53 AM | W_MOMENTUM=0.9
10/22 12:32:53 AM | W_WEIGHT_DECAY=0.0003
10/22 12:32:53 AM | WORKERS=1
10/22 12:32:53 AM | WORLD_SIZE=2
10/22 12:32:53 AM | 
10/22 12:32:53 AM | Logger is set - training start
10/22 12:33:48 AM | 
10/22 12:33:48 AM | Parameters:
10/22 12:33:48 AM | ALPHA_LR=0.0003
10/22 12:33:48 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:33:48 AM | AUX_WEIGHT=0.4
10/22 12:33:48 AM | BATCH_SIZE=64
10/22 12:33:48 AM | CELLS_NUM=3
10/22 12:33:48 AM | CLEAN_ARCH=True
10/22 12:33:48 AM | CUTOUT_LENGTH=16
10/22 12:33:48 AM | DATA_DIR=./cifar
10/22 12:33:48 AM | DATA_PATH=./data/
10/22 12:33:48 AM | DATASET=cifar10
10/22 12:33:48 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 12:33:48 AM | DISTRIBUTED=True
10/22 12:33:48 AM | DROP_PATH_PROB=0.2
10/22 12:33:48 AM | ENSEMBLE=True
10/22 12:33:48 AM | GPUS=[0]
10/22 12:33:48 AM | INIT_CHANNELS=16
10/22 12:33:48 AM | INPUT_CHANNELS=3
10/22 12:33:48 AM | LAYER_NUM=3
10/22 12:33:48 AM | LOCAL_RANK=0
10/22 12:33:48 AM | LR_RATIO=0.5
10/22 12:33:48 AM | MODEL_TYPE=cifar
10/22 12:33:48 AM | N_CLASSES=10
10/22 12:33:48 AM | NAME=cifar10-search
10/22 12:33:48 AM | NO_REPEAT=False
10/22 12:33:48 AM | PATH=searchs/cifar10-search
10/22 12:33:48 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:33:48 AM | PRETRAIN_DECAY=0
10/22 12:33:48 AM | PRETRAIN_EPOCHS=0
10/22 12:33:48 AM | PRINT_FREQ=10
10/22 12:33:48 AM | RETRAIN_EPOCHS=1
10/22 12:33:48 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:33:48 AM | RETRAIN_SETTING=0
10/22 12:33:48 AM | RETRAIN_UPDATE_W=True
10/22 12:33:48 AM | SAME_STRUCTURE=True
10/22 12:33:48 AM | SAMPLE_RATIO=0.2
10/22 12:33:48 AM | SEARCH_ITER=25
10/22 12:33:48 AM | SEARCH_ITER_EPOCHS=1
10/22 12:33:48 AM | SEED=0
10/22 12:33:48 AM | SHORT_CONNECT=False
10/22 12:33:48 AM | SYNC_PARAM=True
10/22 12:33:48 AM | TEACHER2STUDENT=True
10/22 12:33:48 AM | TEST_DIR=/data/imagenet/val
10/22 12:33:48 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:33:48 AM | TRAIN_PORTION=0.5
10/22 12:33:48 AM | UNROLLED=False
10/22 12:33:48 AM | USE_BETA=True
10/22 12:33:48 AM | VAL_DIR=/data/imagenet/train
10/22 12:33:48 AM | W_GRAD_CLIP=5.0
10/22 12:33:48 AM | W_LR=0.05
10/22 12:33:48 AM | W_LR_MIN=0.001
10/22 12:33:48 AM | W_MOMENTUM=0.9
10/22 12:33:48 AM | W_WEIGHT_DECAY=0.0003
10/22 12:33:48 AM | WORKERS=1
10/22 12:33:48 AM | WORLD_SIZE=1
10/22 12:33:48 AM | 
10/22 12:33:48 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
10/22 12:34:41 AM | 
10/22 12:34:41 AM | Parameters:
10/22 12:34:41 AM | ALPHA_LR=0.0003
10/22 12:34:41 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:34:41 AM | AUX_WEIGHT=0.4
10/22 12:34:41 AM | BATCH_SIZE=64
10/22 12:34:41 AM | CELLS_NUM=3
10/22 12:34:41 AM | CLEAN_ARCH=True
10/22 12:34:41 AM | CUTOUT_LENGTH=16
10/22 12:34:41 AM | DATA_DIR=./cifar
10/22 12:34:41 AM | DATA_PATH=./data/
10/22 12:34:41 AM | DATASET=cifar10
10/22 12:34:41 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 12:34:41 AM | DISTRIBUTED=True
10/22 12:34:41 AM | DROP_PATH_PROB=0.2
10/22 12:34:41 AM | ENSEMBLE=True
10/22 12:34:41 AM | GPUS=[0]
10/22 12:34:41 AM | INIT_CHANNELS=16
10/22 12:34:41 AM | INPUT_CHANNELS=3
10/22 12:34:41 AM | LAYER_NUM=3
10/22 12:34:41 AM | LOCAL_RANK=0
10/22 12:34:41 AM | LR_RATIO=0.5
10/22 12:34:41 AM | MODEL_TYPE=cifar
10/22 12:34:41 AM | N_CLASSES=10
10/22 12:34:41 AM | NAME=cifar10-search
10/22 12:34:41 AM | NO_REPEAT=False
10/22 12:34:41 AM | PATH=searchs/cifar10-search
10/22 12:34:41 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:34:41 AM | PRETRAIN_DECAY=0
10/22 12:34:41 AM | PRETRAIN_EPOCHS=0
10/22 12:34:41 AM | PRINT_FREQ=10
10/22 12:34:41 AM | RETRAIN_EPOCHS=1
10/22 12:34:41 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:34:41 AM | RETRAIN_SETTING=0
10/22 12:34:41 AM | RETRAIN_UPDATE_W=True
10/22 12:34:41 AM | SAME_STRUCTURE=True
10/22 12:34:41 AM | SAMPLE_RATIO=0.2
10/22 12:34:41 AM | SEARCH_ITER=25
10/22 12:34:41 AM | SEARCH_ITER_EPOCHS=1
10/22 12:34:41 AM | SEED=0
10/22 12:34:41 AM | SHORT_CONNECT=False
10/22 12:34:41 AM | SYNC_PARAM=True
10/22 12:34:41 AM | TEACHER2STUDENT=True
10/22 12:34:41 AM | TEST_DIR=/data/imagenet/val
10/22 12:34:41 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:34:41 AM | TRAIN_PORTION=0.5
10/22 12:34:41 AM | UNROLLED=False
10/22 12:34:41 AM | USE_BETA=True
10/22 12:34:41 AM | VAL_DIR=/data/imagenet/train
10/22 12:34:41 AM | W_GRAD_CLIP=5.0
10/22 12:34:41 AM | W_LR=0.05
10/22 12:34:41 AM | W_LR_MIN=0.001
10/22 12:34:41 AM | W_MOMENTUM=0.9
10/22 12:34:41 AM | W_WEIGHT_DECAY=0.0003
10/22 12:34:41 AM | WORKERS=1
10/22 12:34:41 AM | WORLD_SIZE=1
10/22 12:34:41 AM | 
10/22 12:34:41 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
10/22 12:37:14 AM | 
10/22 12:37:14 AM | Parameters:
10/22 12:37:14 AM | ALPHA_LR=0.0003
10/22 12:37:14 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:37:14 AM | AUX_WEIGHT=0.4
10/22 12:37:14 AM | BATCH_SIZE=64
10/22 12:37:14 AM | CELLS_NUM=3
10/22 12:37:14 AM | CLEAN_ARCH=True
10/22 12:37:14 AM | CUTOUT_LENGTH=16
10/22 12:37:14 AM | DATA_DIR=./cifar
10/22 12:37:14 AM | DATA_PATH=./data/
10/22 12:37:14 AM | DATASET=cifar10
10/22 12:37:14 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 12:37:14 AM | DISTRIBUTED=True
10/22 12:37:14 AM | DROP_PATH_PROB=0.2
10/22 12:37:14 AM | ENSEMBLE=True
10/22 12:37:14 AM | GPUS=[0]
10/22 12:37:14 AM | INIT_CHANNELS=16
10/22 12:37:14 AM | INPUT_CHANNELS=3
10/22 12:37:14 AM | LAYER_NUM=3
10/22 12:37:14 AM | LOCAL_RANK=0
10/22 12:37:14 AM | LR_RATIO=0.5
10/22 12:37:14 AM | MODEL_TYPE=cifar
10/22 12:37:14 AM | N_CLASSES=10
10/22 12:37:14 AM | NAME=cifar10-search
10/22 12:37:14 AM | NO_REPEAT=False
10/22 12:37:14 AM | PATH=searchs/cifar10-search
10/22 12:37:14 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:37:14 AM | PRETRAIN_DECAY=0
10/22 12:37:14 AM | PRETRAIN_EPOCHS=0
10/22 12:37:14 AM | PRINT_FREQ=10
10/22 12:37:14 AM | RETRAIN_EPOCHS=1
10/22 12:37:14 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:37:14 AM | RETRAIN_SETTING=0
10/22 12:37:14 AM | RETRAIN_UPDATE_W=True
10/22 12:37:14 AM | SAME_STRUCTURE=True
10/22 12:37:14 AM | SAMPLE_RATIO=0.2
10/22 12:37:14 AM | SEARCH_ITER=25
10/22 12:37:14 AM | SEARCH_ITER_EPOCHS=1
10/22 12:37:14 AM | SEED=0
10/22 12:37:14 AM | SHORT_CONNECT=False
10/22 12:37:14 AM | SYNC_PARAM=True
10/22 12:37:14 AM | TEACHER2STUDENT=True
10/22 12:37:14 AM | TEST_DIR=/data/imagenet/val
10/22 12:37:14 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:37:14 AM | TRAIN_PORTION=0.5
10/22 12:37:14 AM | UNROLLED=False
10/22 12:37:14 AM | USE_BETA=True
10/22 12:37:14 AM | VAL_DIR=/data/imagenet/train
10/22 12:37:14 AM | W_GRAD_CLIP=5.0
10/22 12:37:14 AM | W_LR=0.05
10/22 12:37:14 AM | W_LR_MIN=0.001
10/22 12:37:14 AM | W_MOMENTUM=0.9
10/22 12:37:14 AM | W_WEIGHT_DECAY=0.0003
10/22 12:37:14 AM | WORKERS=1
10/22 12:37:14 AM | WORLD_SIZE=1
10/22 12:37:14 AM | 
10/22 12:37:14 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
10/22 12:37:47 AM | 
10/22 12:37:47 AM | Parameters:
10/22 12:37:47 AM | ALPHA_LR=0.0003
10/22 12:37:47 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:37:47 AM | AUX_WEIGHT=0.4
10/22 12:37:47 AM | BATCH_SIZE=64
10/22 12:37:47 AM | CELLS_NUM=3
10/22 12:37:47 AM | CLEAN_ARCH=True
10/22 12:37:47 AM | CUTOUT_LENGTH=16
10/22 12:37:47 AM | DATA_DIR=./cifar
10/22 12:37:47 AM | DATA_PATH=./data/
10/22 12:37:47 AM | DATASET=cifar10
10/22 12:37:47 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 12:37:47 AM | DISTRIBUTED=True
10/22 12:37:47 AM | DROP_PATH_PROB=0.2
10/22 12:37:47 AM | ENSEMBLE=True
10/22 12:37:47 AM | GPUS=[0]
10/22 12:37:47 AM | INIT_CHANNELS=16
10/22 12:37:47 AM | INPUT_CHANNELS=3
10/22 12:37:47 AM | LAYER_NUM=3
10/22 12:37:47 AM | LOCAL_RANK=0
10/22 12:37:47 AM | LR_RATIO=0.5
10/22 12:37:47 AM | MODEL_TYPE=cifar
10/22 12:37:47 AM | N_CLASSES=10
10/22 12:37:47 AM | NAME=cifar10-search
10/22 12:37:47 AM | NO_REPEAT=False
10/22 12:37:47 AM | PATH=searchs/cifar10-search
10/22 12:37:47 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:37:47 AM | PRETRAIN_DECAY=0
10/22 12:37:47 AM | PRETRAIN_EPOCHS=0
10/22 12:37:47 AM | PRINT_FREQ=10
10/22 12:37:47 AM | RETRAIN_EPOCHS=1
10/22 12:37:47 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:37:47 AM | RETRAIN_SETTING=0
10/22 12:37:47 AM | RETRAIN_UPDATE_W=True
10/22 12:37:47 AM | SAME_STRUCTURE=True
10/22 12:37:47 AM | SAMPLE_RATIO=0.2
10/22 12:37:47 AM | SEARCH_ITER=25
10/22 12:37:47 AM | SEARCH_ITER_EPOCHS=1
10/22 12:37:47 AM | SEED=0
10/22 12:37:47 AM | SHORT_CONNECT=False
10/22 12:37:47 AM | SYNC_PARAM=True
10/22 12:37:47 AM | TEACHER2STUDENT=True
10/22 12:37:47 AM | TEST_DIR=/data/imagenet/val
10/22 12:37:47 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:37:47 AM | TRAIN_PORTION=0.5
10/22 12:37:47 AM | UNROLLED=False
10/22 12:37:47 AM | USE_BETA=True
10/22 12:37:47 AM | VAL_DIR=/data/imagenet/train
10/22 12:37:47 AM | W_GRAD_CLIP=5.0
10/22 12:37:47 AM | W_LR=0.05
10/22 12:37:47 AM | W_LR_MIN=0.001
10/22 12:37:47 AM | W_MOMENTUM=0.9
10/22 12:37:47 AM | W_WEIGHT_DECAY=0.0003
10/22 12:37:47 AM | WORKERS=1
10/22 12:37:47 AM | WORLD_SIZE=1
10/22 12:37:47 AM | 
10/22 12:37:47 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
10/22 12:38:25 AM | 
10/22 12:38:25 AM | Parameters:
10/22 12:38:25 AM | ALPHA_LR=0.0003
10/22 12:38:25 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:38:25 AM | AUX_WEIGHT=0.4
10/22 12:38:25 AM | BATCH_SIZE=64
10/22 12:38:25 AM | CELLS_NUM=3
10/22 12:38:25 AM | CLEAN_ARCH=True
10/22 12:38:25 AM | CUTOUT_LENGTH=16
10/22 12:38:25 AM | DATA_DIR=./cifar
10/22 12:38:25 AM | DATA_PATH=./data/
10/22 12:38:25 AM | DATASET=cifar10
10/22 12:38:25 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 12:38:25 AM | DISTRIBUTED=True
10/22 12:38:25 AM | DROP_PATH_PROB=0.2
10/22 12:38:25 AM | ENSEMBLE=True
10/22 12:38:25 AM | GPUS=[0]
10/22 12:38:25 AM | INIT_CHANNELS=16
10/22 12:38:25 AM | INPUT_CHANNELS=3
10/22 12:38:25 AM | LAYER_NUM=3
10/22 12:38:25 AM | LOCAL_RANK=0
10/22 12:38:25 AM | LR_RATIO=0.5
10/22 12:38:25 AM | MODEL_TYPE=cifar
10/22 12:38:25 AM | N_CLASSES=10
10/22 12:38:25 AM | NAME=cifar10-search
10/22 12:38:25 AM | NO_REPEAT=False
10/22 12:38:25 AM | PATH=searchs/cifar10-search
10/22 12:38:25 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:38:25 AM | PRETRAIN_DECAY=0
10/22 12:38:25 AM | PRETRAIN_EPOCHS=0
10/22 12:38:25 AM | PRINT_FREQ=10
10/22 12:38:25 AM | RETRAIN_EPOCHS=1
10/22 12:38:25 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:38:25 AM | RETRAIN_SETTING=0
10/22 12:38:25 AM | RETRAIN_UPDATE_W=True
10/22 12:38:25 AM | SAME_STRUCTURE=True
10/22 12:38:25 AM | SAMPLE_RATIO=0.2
10/22 12:38:25 AM | SEARCH_ITER=25
10/22 12:38:25 AM | SEARCH_ITER_EPOCHS=1
10/22 12:38:25 AM | SEED=0
10/22 12:38:25 AM | SHORT_CONNECT=False
10/22 12:38:25 AM | SYNC_PARAM=True
10/22 12:38:25 AM | TEACHER2STUDENT=True
10/22 12:38:25 AM | TEST_DIR=/data/imagenet/val
10/22 12:38:25 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:38:25 AM | TRAIN_PORTION=0.5
10/22 12:38:25 AM | UNROLLED=False
10/22 12:38:25 AM | USE_BETA=True
10/22 12:38:25 AM | VAL_DIR=/data/imagenet/train
10/22 12:38:25 AM | W_GRAD_CLIP=5.0
10/22 12:38:25 AM | W_LR=0.05
10/22 12:38:25 AM | W_LR_MIN=0.001
10/22 12:38:25 AM | W_MOMENTUM=0.9
10/22 12:38:25 AM | W_WEIGHT_DECAY=0.0003
10/22 12:38:25 AM | WORKERS=1
10/22 12:38:25 AM | WORLD_SIZE=1
10/22 12:38:25 AM | 
10/22 12:38:25 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
10/22 12:41:07 AM | 
10/22 12:41:07 AM | Parameters:
10/22 12:41:07 AM | ALPHA_LR=0.0003
10/22 12:41:07 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:41:07 AM | AUX_WEIGHT=0.4
10/22 12:41:07 AM | BATCH_SIZE=64
10/22 12:41:07 AM | CELLS_NUM=3
10/22 12:41:07 AM | CLEAN_ARCH=True
10/22 12:41:07 AM | CUTOUT_LENGTH=16
10/22 12:41:07 AM | DATA_DIR=./cifar
10/22 12:41:07 AM | DATA_PATH=./data/
10/22 12:41:07 AM | DATASET=cifar10
10/22 12:41:07 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 12:41:07 AM | DISTRIBUTED=True
10/22 12:41:07 AM | DROP_PATH_PROB=0.2
10/22 12:41:07 AM | ENSEMBLE=True
10/22 12:41:07 AM | GPUS=[0]
10/22 12:41:07 AM | INIT_CHANNELS=16
10/22 12:41:07 AM | INPUT_CHANNELS=3
10/22 12:41:07 AM | LAYER_NUM=3
10/22 12:41:07 AM | LOCAL_RANK=0
10/22 12:41:07 AM | LR_RATIO=0.5
10/22 12:41:07 AM | MODEL_TYPE=cifar
10/22 12:41:07 AM | N_CLASSES=10
10/22 12:41:07 AM | NAME=cifar10-search
10/22 12:41:07 AM | NO_REPEAT=False
10/22 12:41:07 AM | PATH=searchs/cifar10-search
10/22 12:41:07 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:41:07 AM | PRETRAIN_DECAY=0
10/22 12:41:07 AM | PRETRAIN_EPOCHS=0
10/22 12:41:07 AM | PRINT_FREQ=10
10/22 12:41:07 AM | RETRAIN_EPOCHS=1
10/22 12:41:07 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:41:07 AM | RETRAIN_SETTING=0
10/22 12:41:07 AM | RETRAIN_UPDATE_W=True
10/22 12:41:07 AM | SAME_STRUCTURE=True
10/22 12:41:07 AM | SAMPLE_RATIO=0.2
10/22 12:41:07 AM | SEARCH_ITER=25
10/22 12:41:07 AM | SEARCH_ITER_EPOCHS=1
10/22 12:41:07 AM | SEED=0
10/22 12:41:07 AM | SHORT_CONNECT=False
10/22 12:41:07 AM | SYNC_PARAM=True
10/22 12:41:07 AM | TEACHER2STUDENT=True
10/22 12:41:07 AM | TEST_DIR=/data/imagenet/val
10/22 12:41:07 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:41:07 AM | TRAIN_PORTION=0.5
10/22 12:41:07 AM | UNROLLED=False
10/22 12:41:07 AM | USE_BETA=True
10/22 12:41:07 AM | VAL_DIR=/data/imagenet/train
10/22 12:41:07 AM | W_GRAD_CLIP=5.0
10/22 12:41:07 AM | W_LR=0.05
10/22 12:41:07 AM | W_LR_MIN=0.001
10/22 12:41:07 AM | W_MOMENTUM=0.9
10/22 12:41:07 AM | W_WEIGHT_DECAY=0.0003
10/22 12:41:07 AM | WORKERS=1
10/22 12:41:07 AM | WORLD_SIZE=1
10/22 12:41:07 AM | 
10/22 12:41:07 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
Train: Layer 1/3 Epoch  1/25 Step 000/391 Loss 2.300 Prec@(1,5) (6.2%, 50.0%)
10/22 12:43:33 AM | 
10/22 12:43:33 AM | Parameters:
10/22 12:43:33 AM | ALPHA_LR=0.0003
10/22 12:43:33 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:43:33 AM | AUX_WEIGHT=0.4
10/22 12:43:33 AM | BATCH_SIZE=64
10/22 12:43:33 AM | CELLS_NUM=3
10/22 12:43:33 AM | CLEAN_ARCH=True
10/22 12:43:33 AM | CUTOUT_LENGTH=16
10/22 12:43:33 AM | DATA_DIR=./cifar
10/22 12:43:33 AM | DATA_PATH=./data/
10/22 12:43:33 AM | DATASET=cifar10
10/22 12:43:33 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 12:43:33 AM | DISTRIBUTED=True
10/22 12:43:33 AM | DROP_PATH_PROB=0.2
10/22 12:43:33 AM | ENSEMBLE=True
10/22 12:43:33 AM | GPUS=[0]
10/22 12:43:33 AM | INIT_CHANNELS=16
10/22 12:43:33 AM | INPUT_CHANNELS=3
10/22 12:43:33 AM | LAYER_NUM=3
10/22 12:43:33 AM | LOCAL_RANK=0
10/22 12:43:33 AM | LR_RATIO=0.5
10/22 12:43:33 AM | MODEL_TYPE=cifar
10/22 12:43:33 AM | N_CLASSES=10
10/22 12:43:33 AM | NAME=cifar10-search
10/22 12:43:33 AM | NO_REPEAT=False
10/22 12:43:33 AM | PATH=searchs/cifar10-search
10/22 12:43:33 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:43:33 AM | PRETRAIN_DECAY=0
10/22 12:43:33 AM | PRETRAIN_EPOCHS=0
10/22 12:43:33 AM | PRINT_FREQ=10
10/22 12:43:33 AM | RETRAIN_EPOCHS=1
10/22 12:43:33 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:43:33 AM | RETRAIN_SETTING=0
10/22 12:43:33 AM | RETRAIN_UPDATE_W=True
10/22 12:43:33 AM | SAME_STRUCTURE=True
10/22 12:43:33 AM | SAMPLE_RATIO=0.2
10/22 12:43:33 AM | SEARCH_ITER=25
10/22 12:43:33 AM | SEARCH_ITER_EPOCHS=1
10/22 12:43:33 AM | SEED=0
10/22 12:43:33 AM | SHORT_CONNECT=False
10/22 12:43:33 AM | SYNC_PARAM=True
10/22 12:43:33 AM | TEACHER2STUDENT=True
10/22 12:43:33 AM | TEST_DIR=/data/imagenet/val
10/22 12:43:33 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:43:33 AM | TRAIN_PORTION=0.5
10/22 12:43:33 AM | UNROLLED=False
10/22 12:43:33 AM | USE_BETA=True
10/22 12:43:33 AM | VAL_DIR=/data/imagenet/train
10/22 12:43:33 AM | W_GRAD_CLIP=5.0
10/22 12:43:33 AM | W_LR=0.05
10/22 12:43:33 AM | W_LR_MIN=0.001
10/22 12:43:33 AM | W_MOMENTUM=0.9
10/22 12:43:33 AM | W_WEIGHT_DECAY=0.0003
10/22 12:43:33 AM | WORKERS=1
10/22 12:43:33 AM | WORLD_SIZE=1
10/22 12:43:33 AM | 
10/22 12:43:33 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
Train: Layer 1/3 Epoch  1/25 Step 000/002 Loss 2.295 Prec@(1,5) (9.4%, 48.4%)
Train: Layer 1/3 Epoch  1/25 Step 001/002 Loss 2.302 Prec@(1,5) (10.9%, 47.7%)
Train: Layer 1/3 Epoch  1/25 Final Prec@1 10.9375%
Stage: 0 Layer: 1 genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Final best Prec@1 = 0.0000%
Stage: 0 Layer: 1 Best Genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
10/22 12:44:42 AM | 
10/22 12:44:42 AM | Parameters:
10/22 12:44:42 AM | ALPHA_LR=0.0003
10/22 12:44:42 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:44:42 AM | AUX_WEIGHT=0.4
10/22 12:44:42 AM | BATCH_SIZE=64
10/22 12:44:42 AM | CELLS_NUM=3
10/22 12:44:42 AM | CLEAN_ARCH=True
10/22 12:44:42 AM | CUTOUT_LENGTH=16
10/22 12:44:42 AM | DATA_DIR=./cifar
10/22 12:44:42 AM | DATA_PATH=./data/
10/22 12:44:42 AM | DATASET=cifar10
10/22 12:44:42 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 12:44:42 AM | DISTRIBUTED=True
10/22 12:44:42 AM | DROP_PATH_PROB=0.2
10/22 12:44:42 AM | ENSEMBLE=True
10/22 12:44:42 AM | GPUS=[0]
10/22 12:44:42 AM | INIT_CHANNELS=16
10/22 12:44:42 AM | INPUT_CHANNELS=3
10/22 12:44:42 AM | LAYER_NUM=3
10/22 12:44:42 AM | LOCAL_RANK=0
10/22 12:44:42 AM | LR_RATIO=0.5
10/22 12:44:42 AM | MODEL_TYPE=cifar
10/22 12:44:42 AM | N_CLASSES=10
10/22 12:44:42 AM | NAME=cifar10-search
10/22 12:44:42 AM | NO_REPEAT=False
10/22 12:44:42 AM | PATH=searchs/cifar10-search
10/22 12:44:42 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:44:42 AM | PRETRAIN_DECAY=0
10/22 12:44:42 AM | PRETRAIN_EPOCHS=0
10/22 12:44:42 AM | PRINT_FREQ=10
10/22 12:44:42 AM | RETRAIN_EPOCHS=1
10/22 12:44:42 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:44:42 AM | RETRAIN_SETTING=0
10/22 12:44:42 AM | RETRAIN_UPDATE_W=True
10/22 12:44:42 AM | SAME_STRUCTURE=True
10/22 12:44:42 AM | SAMPLE_RATIO=0.2
10/22 12:44:42 AM | SEARCH_ITER=25
10/22 12:44:42 AM | SEARCH_ITER_EPOCHS=1
10/22 12:44:42 AM | SEED=0
10/22 12:44:42 AM | SHORT_CONNECT=False
10/22 12:44:42 AM | SYNC_PARAM=True
10/22 12:44:42 AM | TEACHER2STUDENT=True
10/22 12:44:42 AM | TEST_DIR=/data/imagenet/val
10/22 12:44:42 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:44:42 AM | TRAIN_PORTION=0.5
10/22 12:44:42 AM | UNROLLED=False
10/22 12:44:42 AM | USE_BETA=True
10/22 12:44:42 AM | VAL_DIR=/data/imagenet/train
10/22 12:44:42 AM | W_GRAD_CLIP=5.0
10/22 12:44:42 AM | W_LR=0.05
10/22 12:44:42 AM | W_LR_MIN=0.001
10/22 12:44:42 AM | W_MOMENTUM=0.9
10/22 12:44:42 AM | W_WEIGHT_DECAY=0.0003
10/22 12:44:42 AM | WORKERS=1
10/22 12:44:42 AM | WORLD_SIZE=1
10/22 12:44:42 AM | 
10/22 12:44:42 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
Train: Layer 1/3 Epoch  1/25 Step 000/002 Loss 2.295 Prec@(1,5) (9.4%, 48.4%)
Train: Layer 1/3 Epoch  1/25 Step 001/002 Loss 2.302 Prec@(1,5) (10.9%, 47.7%)
Train: Layer 1/3 Epoch  1/25 Final Prec@1 10.9375%
Stage: 0 Layer: 1 genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
10/22 12:46:37 AM | 
10/22 12:46:37 AM | Parameters:
10/22 12:46:37 AM | ALPHA_LR=0.0003
10/22 12:46:37 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:46:37 AM | AUX_WEIGHT=0.4
10/22 12:46:37 AM | BATCH_SIZE=64
10/22 12:46:37 AM | CELLS_NUM=3
10/22 12:46:37 AM | CLEAN_ARCH=True
10/22 12:46:37 AM | CUTOUT_LENGTH=16
10/22 12:46:37 AM | DATA_DIR=./cifar
10/22 12:46:37 AM | DATA_PATH=./data/
10/22 12:46:37 AM | DATASET=cifar10
10/22 12:46:37 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 12:46:37 AM | DISTRIBUTED=True
10/22 12:46:37 AM | DROP_PATH_PROB=0.2
10/22 12:46:37 AM | ENSEMBLE=True
10/22 12:46:37 AM | GPUS=[0]
10/22 12:46:37 AM | INIT_CHANNELS=16
10/22 12:46:37 AM | INPUT_CHANNELS=3
10/22 12:46:37 AM | LAYER_NUM=3
10/22 12:46:37 AM | LOCAL_RANK=0
10/22 12:46:37 AM | LR_RATIO=0.5
10/22 12:46:37 AM | MODEL_TYPE=cifar
10/22 12:46:37 AM | N_CLASSES=10
10/22 12:46:37 AM | NAME=cifar10-search
10/22 12:46:37 AM | NO_REPEAT=False
10/22 12:46:37 AM | PATH=searchs/cifar10-search
10/22 12:46:37 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:46:37 AM | PRETRAIN_DECAY=0
10/22 12:46:37 AM | PRETRAIN_EPOCHS=0
10/22 12:46:37 AM | PRINT_FREQ=10
10/22 12:46:37 AM | RETRAIN_EPOCHS=1
10/22 12:46:37 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:46:37 AM | RETRAIN_SETTING=0
10/22 12:46:37 AM | RETRAIN_UPDATE_W=True
10/22 12:46:37 AM | SAME_STRUCTURE=True
10/22 12:46:37 AM | SAMPLE_RATIO=0.2
10/22 12:46:37 AM | SEARCH_ITER=25
10/22 12:46:37 AM | SEARCH_ITER_EPOCHS=1
10/22 12:46:37 AM | SEED=0
10/22 12:46:37 AM | SHORT_CONNECT=False
10/22 12:46:37 AM | SYNC_PARAM=True
10/22 12:46:37 AM | TEACHER2STUDENT=True
10/22 12:46:37 AM | TEST_DIR=/data/imagenet/val
10/22 12:46:37 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:46:37 AM | TRAIN_PORTION=0.5
10/22 12:46:37 AM | UNROLLED=False
10/22 12:46:37 AM | USE_BETA=True
10/22 12:46:37 AM | VAL_DIR=/data/imagenet/train
10/22 12:46:37 AM | W_GRAD_CLIP=5.0
10/22 12:46:37 AM | W_LR=0.05
10/22 12:46:37 AM | W_LR_MIN=0.001
10/22 12:46:37 AM | W_MOMENTUM=0.9
10/22 12:46:37 AM | W_WEIGHT_DECAY=0.0003
10/22 12:46:37 AM | WORKERS=1
10/22 12:46:37 AM | WORLD_SIZE=1
10/22 12:46:37 AM | 
10/22 12:46:37 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
Train: Layer 1/3 Epoch  1/25 Step 000/002 Loss 2.295 Prec@(1,5) (9.4%, 48.4%)
Train: Layer 1/3 Epoch  1/25 Step 001/002 Loss 2.302 Prec@(1,5) (10.9%, 47.7%)
Train: Layer 1/3 Epoch  1/25 Final Prec@1 10.9375%
Stage: 0 Layer: 1 genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Final best Prec@1 = 0.0000%
Stage: 0 Layer: 1 Best Genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
10/22 12:47:58 AM | 
10/22 12:47:58 AM | Parameters:
10/22 12:47:58 AM | ALPHA_LR=0.0003
10/22 12:47:58 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:47:58 AM | AUX_WEIGHT=0.4
10/22 12:47:58 AM | BATCH_SIZE=64
10/22 12:47:58 AM | CELLS_NUM=3
10/22 12:47:58 AM | CLEAN_ARCH=True
10/22 12:47:58 AM | CUTOUT_LENGTH=16
10/22 12:47:58 AM | DATA_DIR=./cifar
10/22 12:47:58 AM | DATA_PATH=./data/
10/22 12:47:58 AM | DATASET=cifar10
10/22 12:47:58 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 12:47:58 AM | DISTRIBUTED=True
10/22 12:47:58 AM | DROP_PATH_PROB=0.2
10/22 12:47:58 AM | ENSEMBLE=True
10/22 12:47:58 AM | GPUS=[0]
10/22 12:47:58 AM | INIT_CHANNELS=16
10/22 12:47:58 AM | INPUT_CHANNELS=3
10/22 12:47:58 AM | LAYER_NUM=3
10/22 12:47:58 AM | LOCAL_RANK=0
10/22 12:47:58 AM | LR_RATIO=0.5
10/22 12:47:58 AM | MODEL_TYPE=cifar
10/22 12:47:58 AM | N_CLASSES=10
10/22 12:47:58 AM | NAME=cifar10-search
10/22 12:47:58 AM | NO_REPEAT=False
10/22 12:47:58 AM | PATH=searchs/cifar10-search
10/22 12:47:58 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:47:58 AM | PRETRAIN_DECAY=0
10/22 12:47:58 AM | PRETRAIN_EPOCHS=0
10/22 12:47:58 AM | PRINT_FREQ=10
10/22 12:47:58 AM | RETRAIN_EPOCHS=1
10/22 12:47:58 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:47:58 AM | RETRAIN_SETTING=0
10/22 12:47:58 AM | RETRAIN_UPDATE_W=True
10/22 12:47:58 AM | SAME_STRUCTURE=True
10/22 12:47:58 AM | SAMPLE_RATIO=0.2
10/22 12:47:58 AM | SEARCH_ITER=25
10/22 12:47:58 AM | SEARCH_ITER_EPOCHS=1
10/22 12:47:58 AM | SEED=0
10/22 12:47:58 AM | SHORT_CONNECT=False
10/22 12:47:58 AM | SYNC_PARAM=True
10/22 12:47:58 AM | TEACHER2STUDENT=True
10/22 12:47:58 AM | TEST_DIR=/data/imagenet/val
10/22 12:47:58 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:47:58 AM | TRAIN_PORTION=0.5
10/22 12:47:58 AM | UNROLLED=False
10/22 12:47:58 AM | USE_BETA=True
10/22 12:47:58 AM | VAL_DIR=/data/imagenet/train
10/22 12:47:58 AM | W_GRAD_CLIP=5.0
10/22 12:47:58 AM | W_LR=0.05
10/22 12:47:58 AM | W_LR_MIN=0.001
10/22 12:47:58 AM | W_MOMENTUM=0.9
10/22 12:47:58 AM | W_WEIGHT_DECAY=0.0003
10/22 12:47:58 AM | WORKERS=1
10/22 12:47:58 AM | WORLD_SIZE=1
10/22 12:47:58 AM | 
10/22 12:47:58 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
Train: Layer 1/3 Epoch  1/25 Step 000/002 Loss 2.295 Prec@(1,5) (9.4%, 48.4%)
Train: Layer 1/3 Epoch  1/25 Step 001/002 Loss 2.302 Prec@(1,5) (10.9%, 47.7%)
Train: Layer 1/3 Epoch  1/25 Final Prec@1 10.9375%
Stage: 0 Layer: 1 genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Final best Prec@1 = 0.0000%
Stage: 0 Layer: 1 Best Genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1248, 0.1249, 0.1254, 0.1250, 0.1249, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251, 0.1248, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250, 0.1248],
        [0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1246, 0.1251],
        [0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1251],
        [0.1249, 0.1250, 0.1252, 0.1251, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1247, 0.1249, 0.1251, 0.1251, 0.1250, 0.1250, 0.1250, 0.1252],
        [0.1249, 0.1250, 0.1249, 0.1251, 0.1249, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1252, 0.1252, 0.1249, 0.1249, 0.1248, 0.1252],
        [0.1252, 0.1250, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1249, 0.1249, 0.1252, 0.1250, 0.1252, 0.1249, 0.1248],
        [0.1248, 0.1253, 0.1249, 0.1249, 0.1251, 0.1252, 0.1248, 0.1250],
        [0.1249, 0.1249, 0.1252, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1251, 0.1250, 0.1249, 0.1248, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1249, 0.1250, 0.1250, 0.1252, 0.1251, 0.1251],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1253, 0.1249, 0.1250],
        [0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1251, 0.1249, 0.1251, 0.1250, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1249, 0.1250, 0.1252, 0.1250],
        [0.1249, 0.1249, 0.1250, 0.1251, 0.1251, 0.1250, 0.1250, 0.1251],
        [0.1249, 0.1250, 0.1250, 0.1250, 0.1252, 0.1252, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1249, 0.1249, 0.1250, 0.1252, 0.1249, 0.1252],
        [0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1251, 0.1251, 0.1248],
        [0.1251, 0.1251, 0.1248, 0.1249, 0.1248, 0.1251, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5004, 0.4996], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3332, 0.3329, 0.3339], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2503, 0.2499, 0.2498], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2000, 0.1998, 0.2001, 0.2001], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4999, 0.5001], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3336, 0.3327, 0.3337], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2502, 0.2498], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2000, 0.1998, 0.2001], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1251, 0.1248, 0.1252, 0.1252, 0.1250, 0.1248, 0.1249],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1248, 0.1250, 0.1252, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1247, 0.1250, 0.1250, 0.1254, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1252, 0.1248, 0.1249, 0.1249],
        [0.1251, 0.1251, 0.1250, 0.1248, 0.1251, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1253, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1250, 0.1247, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1250, 0.1252],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251, 0.1250, 0.1252],
        [0.1249, 0.1249, 0.1249, 0.1253, 0.1251, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1248, 0.1251],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1250, 0.1247, 0.1252, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1252, 0.1249, 0.1249, 0.1252, 0.1248, 0.1252, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1252, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251],
        [0.1249, 0.1250, 0.1250, 0.1250, 0.1252, 0.1251, 0.1248, 0.1250],
        [0.1248, 0.1249, 0.1250, 0.1249, 0.1249, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1248, 0.1251, 0.1251, 0.1249, 0.1248, 0.1253, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5004, 0.4996], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3333, 0.3338, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2496, 0.2501, 0.2499, 0.2504], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1998, 0.2001, 0.2000, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4998, 0.5002], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3332, 0.3335, 0.3333], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2499, 0.2498, 0.2498, 0.2504], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2002, 0.1999, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1249, 0.1250],
        [0.1248, 0.1248, 0.1248, 0.1252, 0.1250, 0.1251, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1251, 0.1250],
        [0.1249, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1251, 0.1249, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1248, 0.1252, 0.1252, 0.1250, 0.1248, 0.1252],
        [0.1250, 0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1248, 0.1252],
        [0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251],
        [0.1247, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1252, 0.1250, 0.1249, 0.1252, 0.1249, 0.1250, 0.1248],
        [0.1250, 0.1248, 0.1252, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1249, 0.1250, 0.1249, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5002, 0.4998], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3331, 0.3333], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2504, 0.2498, 0.2497, 0.2502], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2002, 0.1997, 0.1998, 0.2000, 0.2003], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
Train: Layer 1/3 Epoch  2/25 Step 000/002 Loss 2.273 Prec@(1,5) (18.8%, 60.9%)
Train: Layer 1/3 Epoch  2/25 Step 001/002 Loss 2.270 Prec@(1,5) (18.0%, 55.5%)
Train: Layer 1/3 Epoch  2/25 Final Prec@1 17.9688%
Stage: 0 Layer: 1 genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('max_pool_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 4), ('avg_pool_3x3', 1)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('avg_pool_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 3), ('dil_conv_3x3', 1)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_3x3', 2), ('sep_conv_5x5', 1)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('dil_conv_5x5', 4), ('avg_pool_3x3', 0)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Final best Prec@1 = 0.0000%
Stage: 0 Layer: 1 Best Genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('max_pool_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 4), ('avg_pool_3x3', 1)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('avg_pool_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 3), ('dil_conv_3x3', 1)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_3x3', 2), ('sep_conv_5x5', 1)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('dil_conv_5x5', 4), ('avg_pool_3x3', 0)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1248, 0.1249, 0.1255, 0.1250, 0.1249, 0.1249, 0.1250, 0.1251],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1248, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1251, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248],
        [0.1249, 0.1249, 0.1251, 0.1251, 0.1249, 0.1252, 0.1247, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1252, 0.1249, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1246, 0.1248, 0.1251, 0.1250, 0.1251, 0.1251, 0.1251, 0.1252],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1252, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1249, 0.1250, 0.1252, 0.1249, 0.1252, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1249, 0.1248, 0.1251, 0.1251, 0.1249, 0.1251],
        [0.1249, 0.1249, 0.1251, 0.1249, 0.1251, 0.1251, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1253, 0.1251, 0.1249],
        [0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1249, 0.1250, 0.1250, 0.1252, 0.1251, 0.1251],
        [0.1250, 0.1249, 0.1248, 0.1249, 0.1251, 0.1254, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1248, 0.1252, 0.1251, 0.1251, 0.1251],
        [0.1251, 0.1250, 0.1247, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1248, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1250, 0.1251],
        [0.1248, 0.1249, 0.1250, 0.1250, 0.1252, 0.1252, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1252, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1248],
        [0.1249, 0.1252, 0.1251, 0.1251, 0.1248, 0.1251, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1249, 0.1249, 0.1250, 0.1251, 0.1249, 0.1252],
        [0.1251, 0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1248],
        [0.1251, 0.1252, 0.1248, 0.1248, 0.1247, 0.1252, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5003, 0.4997], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3329, 0.3337], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2503, 0.2498, 0.2498], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1999, 0.1998, 0.2002, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4999, 0.5001], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3328, 0.3337], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2502, 0.2499, 0.2502, 0.2498], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2001, 0.2001, 0.1997, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1251, 0.1249, 0.1253, 0.1252, 0.1250, 0.1248, 0.1249],
        [0.1249, 0.1252, 0.1250, 0.1249, 0.1248, 0.1250, 0.1251, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1247, 0.1250, 0.1250, 0.1254, 0.1252, 0.1246, 0.1249, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1252, 0.1248, 0.1248, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1252, 0.1251, 0.1249, 0.1250, 0.1248, 0.1251, 0.1249],
        [0.1251, 0.1253, 0.1252, 0.1249, 0.1249, 0.1248, 0.1249, 0.1248],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1247, 0.1251, 0.1250, 0.1251],
        [0.1251, 0.1253, 0.1249, 0.1249, 0.1251, 0.1249, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1250, 0.1247, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1247, 0.1251, 0.1249, 0.1250, 0.1252],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1249, 0.1249, 0.1249, 0.1253, 0.1251, 0.1251, 0.1249, 0.1248],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1250, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1251],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1250, 0.1247, 0.1252, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1252, 0.1249, 0.1249, 0.1252, 0.1248, 0.1252, 0.1249],
        [0.1249, 0.1251, 0.1249, 0.1248, 0.1252, 0.1249, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1251, 0.1249, 0.1249, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1250, 0.1251, 0.1248, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1249, 0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1251],
        [0.1249, 0.1252, 0.1248, 0.1252, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1251, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1250, 0.1249, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1250, 0.1250, 0.1251, 0.1253, 0.1251, 0.1247, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1249, 0.1249, 0.1250, 0.1252, 0.1252],
        [0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1254, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5002, 0.4998], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3333, 0.3338, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2495, 0.2501, 0.2499, 0.2506], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1998, 0.2002, 0.1999, 0.2002, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4998, 0.5002], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3332, 0.3335, 0.3333], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2499, 0.2499, 0.2498, 0.2504], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1998, 0.2001, 0.2003, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1251, 0.1250, 0.1253, 0.1248, 0.1250, 0.1249, 0.1251],
        [0.1247, 0.1248, 0.1248, 0.1252, 0.1251, 0.1251, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1249, 0.1249, 0.1251, 0.1249, 0.1251, 0.1251, 0.1251],
        [0.1249, 0.1249, 0.1249, 0.1251, 0.1252, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1249, 0.1253, 0.1249, 0.1248, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1248, 0.1252, 0.1252, 0.1249, 0.1248, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1250, 0.1248, 0.1252],
        [0.1248, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1249, 0.1252],
        [0.1246, 0.1249, 0.1250, 0.1250, 0.1251, 0.1252, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1252, 0.1251, 0.1249, 0.1252, 0.1248, 0.1250, 0.1248],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1249, 0.1250, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1251, 0.1249, 0.1251, 0.1251, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1249, 0.1248, 0.1252, 0.1251],
        [0.1251, 0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3333, 0.3334, 0.3333], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2496, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2003, 0.1997, 0.1998, 0.1998, 0.2004], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
10/22 12:48:58 AM | 
10/22 12:48:58 AM | Parameters:
10/22 12:48:58 AM | ALPHA_LR=0.0003
10/22 12:48:58 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:48:58 AM | AUX_WEIGHT=0.4
10/22 12:48:58 AM | BATCH_SIZE=64
10/22 12:48:58 AM | CELLS_NUM=3
10/22 12:48:58 AM | CLEAN_ARCH=True
10/22 12:48:58 AM | CUTOUT_LENGTH=16
10/22 12:48:58 AM | DATA_DIR=./cifar
10/22 12:48:58 AM | DATA_PATH=./data/
10/22 12:48:58 AM | DATASET=cifar10
10/22 12:48:58 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 12:48:58 AM | DISTRIBUTED=True
10/22 12:48:58 AM | DROP_PATH_PROB=0.2
10/22 12:48:58 AM | ENSEMBLE=True
10/22 12:48:58 AM | GPUS=[0]
10/22 12:48:58 AM | INIT_CHANNELS=16
10/22 12:48:58 AM | INPUT_CHANNELS=3
10/22 12:48:58 AM | LAYER_NUM=3
10/22 12:48:58 AM | LOCAL_RANK=0
10/22 12:48:58 AM | LR_RATIO=0.5
10/22 12:48:58 AM | MODEL_TYPE=cifar
10/22 12:48:58 AM | N_CLASSES=10
10/22 12:48:58 AM | NAME=cifar10-search
10/22 12:48:58 AM | NO_REPEAT=False
10/22 12:48:58 AM | PATH=searchs/cifar10-search
10/22 12:48:58 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:48:58 AM | PRETRAIN_DECAY=0
10/22 12:48:58 AM | PRETRAIN_EPOCHS=0
10/22 12:48:58 AM | PRINT_FREQ=10
10/22 12:48:58 AM | RETRAIN_EPOCHS=1
10/22 12:48:58 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:48:58 AM | RETRAIN_SETTING=0
10/22 12:48:58 AM | RETRAIN_UPDATE_W=True
10/22 12:48:58 AM | SAME_STRUCTURE=True
10/22 12:48:58 AM | SAMPLE_RATIO=0.2
10/22 12:48:58 AM | SEARCH_ITER=25
10/22 12:48:58 AM | SEARCH_ITER_EPOCHS=1
10/22 12:48:58 AM | SEED=0
10/22 12:48:58 AM | SHORT_CONNECT=False
10/22 12:48:58 AM | SYNC_PARAM=True
10/22 12:48:58 AM | TEACHER2STUDENT=True
10/22 12:48:58 AM | TEST_DIR=/data/imagenet/val
10/22 12:48:58 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:48:58 AM | TRAIN_PORTION=0.5
10/22 12:48:58 AM | UNROLLED=False
10/22 12:48:58 AM | USE_BETA=True
10/22 12:48:58 AM | VAL_DIR=/data/imagenet/train
10/22 12:48:58 AM | W_GRAD_CLIP=5.0
10/22 12:48:58 AM | W_LR=0.05
10/22 12:48:58 AM | W_LR_MIN=0.001
10/22 12:48:58 AM | W_MOMENTUM=0.9
10/22 12:48:58 AM | W_WEIGHT_DECAY=0.0003
10/22 12:48:58 AM | WORKERS=1
10/22 12:48:58 AM | WORLD_SIZE=1
10/22 12:48:58 AM | 
10/22 12:48:58 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
10/22 12:49:16 AM | 
10/22 12:49:16 AM | Parameters:
10/22 12:49:16 AM | ALPHA_LR=0.0003
10/22 12:49:16 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:49:16 AM | AUX_WEIGHT=0.4
10/22 12:49:16 AM | BATCH_SIZE=64
10/22 12:49:16 AM | CELLS_NUM=3
10/22 12:49:16 AM | CLEAN_ARCH=True
10/22 12:49:16 AM | CUTOUT_LENGTH=16
10/22 12:49:16 AM | DATA_DIR=./cifar
10/22 12:49:16 AM | DATA_PATH=./data/
10/22 12:49:16 AM | DATASET=cifar10
10/22 12:49:16 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 12:49:16 AM | DISTRIBUTED=True
10/22 12:49:16 AM | DROP_PATH_PROB=0.2
10/22 12:49:16 AM | ENSEMBLE=True
10/22 12:49:16 AM | GPUS=[0]
10/22 12:49:16 AM | INIT_CHANNELS=16
10/22 12:49:16 AM | INPUT_CHANNELS=3
10/22 12:49:16 AM | LAYER_NUM=3
10/22 12:49:16 AM | LOCAL_RANK=0
10/22 12:49:16 AM | LR_RATIO=0.5
10/22 12:49:16 AM | MODEL_TYPE=cifar
10/22 12:49:16 AM | N_CLASSES=10
10/22 12:49:16 AM | NAME=cifar10-search
10/22 12:49:16 AM | NO_REPEAT=False
10/22 12:49:16 AM | PATH=searchs/cifar10-search
10/22 12:49:16 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:49:16 AM | PRETRAIN_DECAY=0
10/22 12:49:16 AM | PRETRAIN_EPOCHS=0
10/22 12:49:16 AM | PRINT_FREQ=10
10/22 12:49:16 AM | RETRAIN_EPOCHS=1
10/22 12:49:16 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:49:16 AM | RETRAIN_SETTING=0
10/22 12:49:16 AM | RETRAIN_UPDATE_W=True
10/22 12:49:16 AM | SAME_STRUCTURE=True
10/22 12:49:16 AM | SAMPLE_RATIO=0.2
10/22 12:49:16 AM | SEARCH_ITER=25
10/22 12:49:16 AM | SEARCH_ITER_EPOCHS=1
10/22 12:49:16 AM | SEED=0
10/22 12:49:16 AM | SHORT_CONNECT=False
10/22 12:49:16 AM | SYNC_PARAM=True
10/22 12:49:16 AM | TEACHER2STUDENT=True
10/22 12:49:16 AM | TEST_DIR=/data/imagenet/val
10/22 12:49:16 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:49:16 AM | TRAIN_PORTION=0.5
10/22 12:49:16 AM | UNROLLED=False
10/22 12:49:16 AM | USE_BETA=True
10/22 12:49:16 AM | VAL_DIR=/data/imagenet/train
10/22 12:49:16 AM | W_GRAD_CLIP=5.0
10/22 12:49:16 AM | W_LR=0.05
10/22 12:49:16 AM | W_LR_MIN=0.001
10/22 12:49:16 AM | W_MOMENTUM=0.9
10/22 12:49:16 AM | W_WEIGHT_DECAY=0.0003
10/22 12:49:16 AM | WORKERS=1
10/22 12:49:16 AM | WORLD_SIZE=1
10/22 12:49:16 AM | 
10/22 12:49:16 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
Train: Layer 1/3 Epoch  1/25 Step 000/002 Loss 2.295 Prec@(1,5) (9.4%, 48.4%)
Train: Layer 1/3 Epoch  1/25 Step 001/002 Loss 2.302 Prec@(1,5) (10.9%, 47.7%)
Train: Layer 1/3 Epoch  1/25 Final Prec@1 10.9375%
Stage: 0 Layer: 1 genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Final best Prec@1 = 0.0000%
Stage: 0 Layer: 1 Best Genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
10/22 12:49:46 AM | 
10/22 12:49:46 AM | Parameters:
10/22 12:49:46 AM | ALPHA_LR=0.0003
10/22 12:49:46 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:49:46 AM | AUX_WEIGHT=0.4
10/22 12:49:46 AM | BATCH_SIZE=64
10/22 12:49:46 AM | CELLS_NUM=3
10/22 12:49:46 AM | CLEAN_ARCH=True
10/22 12:49:46 AM | CUTOUT_LENGTH=16
10/22 12:49:46 AM | DATA_DIR=./cifar
10/22 12:49:46 AM | DATA_PATH=./data/
10/22 12:49:46 AM | DATASET=cifar10
10/22 12:49:46 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 12:49:46 AM | DISTRIBUTED=True
10/22 12:49:46 AM | DROP_PATH_PROB=0.2
10/22 12:49:46 AM | ENSEMBLE=True
10/22 12:49:46 AM | GPUS=[0]
10/22 12:49:46 AM | INIT_CHANNELS=16
10/22 12:49:46 AM | INPUT_CHANNELS=3
10/22 12:49:46 AM | LAYER_NUM=3
10/22 12:49:46 AM | LOCAL_RANK=0
10/22 12:49:46 AM | LR_RATIO=0.5
10/22 12:49:46 AM | MODEL_TYPE=cifar
10/22 12:49:46 AM | N_CLASSES=10
10/22 12:49:46 AM | NAME=cifar10-search
10/22 12:49:46 AM | NO_REPEAT=False
10/22 12:49:46 AM | PATH=searchs/cifar10-search
10/22 12:49:46 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:49:46 AM | PRETRAIN_DECAY=0
10/22 12:49:46 AM | PRETRAIN_EPOCHS=0
10/22 12:49:46 AM | PRINT_FREQ=10
10/22 12:49:46 AM | RETRAIN_EPOCHS=1
10/22 12:49:46 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:49:46 AM | RETRAIN_SETTING=0
10/22 12:49:46 AM | RETRAIN_UPDATE_W=True
10/22 12:49:46 AM | SAME_STRUCTURE=True
10/22 12:49:46 AM | SAMPLE_RATIO=0.2
10/22 12:49:46 AM | SEARCH_ITER=25
10/22 12:49:46 AM | SEARCH_ITER_EPOCHS=1
10/22 12:49:46 AM | SEED=0
10/22 12:49:46 AM | SHORT_CONNECT=False
10/22 12:49:46 AM | SYNC_PARAM=True
10/22 12:49:46 AM | TEACHER2STUDENT=True
10/22 12:49:46 AM | TEST_DIR=/data/imagenet/val
10/22 12:49:46 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:49:46 AM | TRAIN_PORTION=0.5
10/22 12:49:46 AM | UNROLLED=False
10/22 12:49:46 AM | USE_BETA=True
10/22 12:49:46 AM | VAL_DIR=/data/imagenet/train
10/22 12:49:46 AM | W_GRAD_CLIP=5.0
10/22 12:49:46 AM | W_LR=0.05
10/22 12:49:46 AM | W_LR_MIN=0.001
10/22 12:49:46 AM | W_MOMENTUM=0.9
10/22 12:49:46 AM | W_WEIGHT_DECAY=0.0003
10/22 12:49:46 AM | WORKERS=1
10/22 12:49:46 AM | WORLD_SIZE=1
10/22 12:49:46 AM | 
10/22 12:49:46 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
Train: Layer 1/3 Epoch  1/25 Step 000/002 Loss 2.295 Prec@(1,5) (9.4%, 48.4%)
Train: Layer 1/3 Epoch  1/25 Step 001/002 Loss 2.302 Prec@(1,5) (10.9%, 47.7%)
Train: Layer 1/3 Epoch  1/25 Final Prec@1 10.9375%
Stage: 0 Layer: 1 genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Final best Prec@1 = 0.0000%
Stage: 0 Layer: 1 Best Genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
10/22 12:51:31 AM | 
10/22 12:51:31 AM | Parameters:
10/22 12:51:31 AM | ALPHA_LR=0.0003
10/22 12:51:31 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:51:31 AM | AUX_WEIGHT=0.4
10/22 12:51:31 AM | BATCH_SIZE=64
10/22 12:51:31 AM | CELLS_NUM=3
10/22 12:51:31 AM | CLEAN_ARCH=True
10/22 12:51:31 AM | CUTOUT_LENGTH=16
10/22 12:51:31 AM | DATA_DIR=./cifar
10/22 12:51:31 AM | DATA_PATH=./data/
10/22 12:51:31 AM | DATASET=cifar10
10/22 12:51:31 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 12:51:31 AM | DISTRIBUTED=True
10/22 12:51:31 AM | DROP_PATH_PROB=0.2
10/22 12:51:31 AM | ENSEMBLE=True
10/22 12:51:31 AM | GPUS=[0]
10/22 12:51:31 AM | INIT_CHANNELS=16
10/22 12:51:31 AM | INPUT_CHANNELS=3
10/22 12:51:31 AM | LAYER_NUM=3
10/22 12:51:31 AM | LOCAL_RANK=0
10/22 12:51:31 AM | LR_RATIO=0.5
10/22 12:51:31 AM | MODEL_TYPE=cifar
10/22 12:51:31 AM | N_CLASSES=10
10/22 12:51:31 AM | NAME=cifar10-search
10/22 12:51:31 AM | NO_REPEAT=False
10/22 12:51:31 AM | PATH=searchs/cifar10-search
10/22 12:51:31 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:51:31 AM | PRETRAIN_DECAY=0
10/22 12:51:31 AM | PRETRAIN_EPOCHS=0
10/22 12:51:31 AM | PRINT_FREQ=10
10/22 12:51:31 AM | RETRAIN_EPOCHS=1
10/22 12:51:31 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:51:31 AM | RETRAIN_SETTING=0
10/22 12:51:31 AM | RETRAIN_UPDATE_W=True
10/22 12:51:31 AM | SAME_STRUCTURE=True
10/22 12:51:31 AM | SAMPLE_RATIO=0.2
10/22 12:51:31 AM | SEARCH_ITER=25
10/22 12:51:31 AM | SEARCH_ITER_EPOCHS=1
10/22 12:51:31 AM | SEED=0
10/22 12:51:31 AM | SHORT_CONNECT=False
10/22 12:51:31 AM | SYNC_PARAM=True
10/22 12:51:31 AM | TEACHER2STUDENT=True
10/22 12:51:31 AM | TEST_DIR=/data/imagenet/val
10/22 12:51:31 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:51:31 AM | TRAIN_PORTION=0.5
10/22 12:51:31 AM | UNROLLED=False
10/22 12:51:31 AM | USE_BETA=True
10/22 12:51:31 AM | VAL_DIR=/data/imagenet/train
10/22 12:51:31 AM | W_GRAD_CLIP=5.0
10/22 12:51:31 AM | W_LR=0.05
10/22 12:51:31 AM | W_LR_MIN=0.001
10/22 12:51:31 AM | W_MOMENTUM=0.9
10/22 12:51:31 AM | W_WEIGHT_DECAY=0.0003
10/22 12:51:31 AM | WORKERS=1
10/22 12:51:31 AM | WORLD_SIZE=1
10/22 12:51:31 AM | 
10/22 12:51:31 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
Train: Layer 1/3 Epoch  1/25 Step 000/002 Loss 2.295 Prec@(1,5) (9.4%, 48.4%)
Train: Layer 1/3 Epoch  1/25 Step 001/002 Loss 2.302 Prec@(1,5) (10.9%, 47.7%)
Train: Layer 1/3 Epoch  1/25 Final Prec@1 10.9375%
Stage: 0 Layer: 1 genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Final best Prec@1 = 0.0000%
Stage: 0 Layer: 1 Best Genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
10/22 12:52:27 AM | 
10/22 12:52:27 AM | Parameters:
10/22 12:52:27 AM | ALPHA_LR=0.0003
10/22 12:52:27 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:52:27 AM | AUX_WEIGHT=0.4
10/22 12:52:27 AM | BATCH_SIZE=64
10/22 12:52:27 AM | CELLS_NUM=3
10/22 12:52:27 AM | CLEAN_ARCH=True
10/22 12:52:27 AM | CUTOUT_LENGTH=16
10/22 12:52:27 AM | DATA_DIR=./cifar
10/22 12:52:27 AM | DATA_PATH=./data/
10/22 12:52:27 AM | DATASET=cifar10
10/22 12:52:27 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 12:52:27 AM | DISTRIBUTED=True
10/22 12:52:27 AM | DROP_PATH_PROB=0.2
10/22 12:52:27 AM | ENSEMBLE=True
10/22 12:52:27 AM | GPUS=[0]
10/22 12:52:27 AM | INIT_CHANNELS=16
10/22 12:52:27 AM | INPUT_CHANNELS=3
10/22 12:52:27 AM | LAYER_NUM=3
10/22 12:52:27 AM | LOCAL_RANK=0
10/22 12:52:27 AM | LR_RATIO=0.5
10/22 12:52:27 AM | MODEL_TYPE=cifar
10/22 12:52:27 AM | N_CLASSES=10
10/22 12:52:27 AM | NAME=cifar10-search
10/22 12:52:27 AM | NO_REPEAT=False
10/22 12:52:27 AM | PATH=searchs/cifar10-search
10/22 12:52:27 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:52:27 AM | PRETRAIN_DECAY=0
10/22 12:52:27 AM | PRETRAIN_EPOCHS=0
10/22 12:52:27 AM | PRINT_FREQ=10
10/22 12:52:27 AM | RETRAIN_EPOCHS=1
10/22 12:52:27 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:52:27 AM | RETRAIN_SETTING=0
10/22 12:52:27 AM | RETRAIN_UPDATE_W=True
10/22 12:52:27 AM | SAME_STRUCTURE=True
10/22 12:52:27 AM | SAMPLE_RATIO=0.2
10/22 12:52:27 AM | SEARCH_ITER=25
10/22 12:52:27 AM | SEARCH_ITER_EPOCHS=1
10/22 12:52:27 AM | SEED=0
10/22 12:52:27 AM | SHORT_CONNECT=False
10/22 12:52:27 AM | SYNC_PARAM=True
10/22 12:52:27 AM | TEACHER2STUDENT=True
10/22 12:52:27 AM | TEST_DIR=/data/imagenet/val
10/22 12:52:27 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:52:27 AM | TRAIN_PORTION=0.5
10/22 12:52:27 AM | UNROLLED=False
10/22 12:52:27 AM | USE_BETA=True
10/22 12:52:27 AM | VAL_DIR=/data/imagenet/train
10/22 12:52:27 AM | W_GRAD_CLIP=5.0
10/22 12:52:27 AM | W_LR=0.05
10/22 12:52:27 AM | W_LR_MIN=0.001
10/22 12:52:27 AM | W_MOMENTUM=0.9
10/22 12:52:27 AM | W_WEIGHT_DECAY=0.0003
10/22 12:52:27 AM | WORKERS=1
10/22 12:52:27 AM | WORLD_SIZE=1
10/22 12:52:27 AM | 
10/22 12:52:27 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
Train: Layer 1/3 Epoch  1/25 Step 000/002 Loss 2.295 Prec@(1,5) (9.4%, 48.4%)
Train: Layer 1/3 Epoch  1/25 Step 001/002 Loss 2.302 Prec@(1,5) (10.9%, 47.7%)
Train: Layer 1/3 Epoch  1/25 Final Prec@1 10.9375%
Stage: 0 Layer: 1 genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Final best Prec@1 = 0.0000%
Stage: 0 Layer: 1 Best Genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
10/22 12:54:00 AM | 
10/22 12:54:00 AM | Parameters:
10/22 12:54:00 AM | ALPHA_LR=0.0003
10/22 12:54:00 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:54:00 AM | AUX_WEIGHT=0.4
10/22 12:54:00 AM | BATCH_SIZE=64
10/22 12:54:00 AM | CELLS_NUM=3
10/22 12:54:00 AM | CLEAN_ARCH=True
10/22 12:54:00 AM | CUTOUT_LENGTH=16
10/22 12:54:00 AM | DATA_DIR=./cifar
10/22 12:54:00 AM | DATA_PATH=./data/
10/22 12:54:00 AM | DATASET=cifar10
10/22 12:54:00 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 12:54:00 AM | DISTRIBUTED=True
10/22 12:54:00 AM | DROP_PATH_PROB=0.2
10/22 12:54:00 AM | ENSEMBLE=True
10/22 12:54:00 AM | GPUS=[0]
10/22 12:54:00 AM | INIT_CHANNELS=16
10/22 12:54:00 AM | INPUT_CHANNELS=3
10/22 12:54:00 AM | LAYER_NUM=3
10/22 12:54:00 AM | LOCAL_RANK=0
10/22 12:54:00 AM | LR_RATIO=0.5
10/22 12:54:00 AM | MODEL_TYPE=cifar
10/22 12:54:00 AM | N_CLASSES=10
10/22 12:54:00 AM | NAME=cifar10-search
10/22 12:54:00 AM | NO_REPEAT=False
10/22 12:54:00 AM | PATH=searchs/cifar10-search
10/22 12:54:00 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:54:00 AM | PRETRAIN_DECAY=0
10/22 12:54:00 AM | PRETRAIN_EPOCHS=0
10/22 12:54:00 AM | PRINT_FREQ=10
10/22 12:54:00 AM | RETRAIN_EPOCHS=1
10/22 12:54:00 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:54:00 AM | RETRAIN_SETTING=0
10/22 12:54:00 AM | RETRAIN_UPDATE_W=True
10/22 12:54:00 AM | SAME_STRUCTURE=True
10/22 12:54:00 AM | SAMPLE_RATIO=0.2
10/22 12:54:00 AM | SEARCH_ITER=25
10/22 12:54:00 AM | SEARCH_ITER_EPOCHS=1
10/22 12:54:00 AM | SEED=0
10/22 12:54:00 AM | SHORT_CONNECT=False
10/22 12:54:00 AM | SYNC_PARAM=True
10/22 12:54:00 AM | TEACHER2STUDENT=True
10/22 12:54:00 AM | TEST_DIR=/data/imagenet/val
10/22 12:54:00 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:54:00 AM | TRAIN_PORTION=0.5
10/22 12:54:00 AM | UNROLLED=False
10/22 12:54:00 AM | USE_BETA=True
10/22 12:54:00 AM | VAL_DIR=/data/imagenet/train
10/22 12:54:00 AM | W_GRAD_CLIP=5.0
10/22 12:54:00 AM | W_LR=0.05
10/22 12:54:00 AM | W_LR_MIN=0.001
10/22 12:54:00 AM | W_MOMENTUM=0.9
10/22 12:54:00 AM | W_WEIGHT_DECAY=0.0003
10/22 12:54:00 AM | WORKERS=1
10/22 12:54:00 AM | WORLD_SIZE=1
10/22 12:54:00 AM | 
10/22 12:54:00 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
Train: Layer 1/3 Epoch  1/25 Step 000/002 Loss 2.295 Prec@(1,5) (9.4%, 48.4%)
Train: Layer 1/3 Epoch  1/25 Step 001/002 Loss 2.302 Prec@(1,5) (10.9%, 47.7%)
Train: Layer 1/3 Epoch  1/25 Final Prec@1 10.9375%
Stage: 0 Layer: 1 genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Final best Prec@1 = 0.0000%
Stage: 0 Layer: 1 Best Genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Retrain Epoch 0 LR 0.05
10/22 12:55:34 AM | 
10/22 12:55:34 AM | Parameters:
10/22 12:55:34 AM | ALPHA_LR=0.0003
10/22 12:55:34 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:55:34 AM | AUX_WEIGHT=0.4
10/22 12:55:34 AM | BATCH_SIZE=64
10/22 12:55:34 AM | CELLS_NUM=3
10/22 12:55:34 AM | CLEAN_ARCH=True
10/22 12:55:34 AM | CUTOUT_LENGTH=16
10/22 12:55:34 AM | DATA_DIR=./cifar
10/22 12:55:34 AM | DATA_PATH=./data/
10/22 12:55:34 AM | DATASET=cifar10
10/22 12:55:34 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 12:55:34 AM | DISTRIBUTED=True
10/22 12:55:34 AM | DROP_PATH_PROB=0.2
10/22 12:55:34 AM | ENSEMBLE=True
10/22 12:55:34 AM | GPUS=[0]
10/22 12:55:34 AM | INIT_CHANNELS=16
10/22 12:55:34 AM | INPUT_CHANNELS=3
10/22 12:55:34 AM | LAYER_NUM=3
10/22 12:55:34 AM | LOCAL_RANK=0
10/22 12:55:34 AM | LR_RATIO=0.5
10/22 12:55:34 AM | MODEL_TYPE=cifar
10/22 12:55:34 AM | N_CLASSES=10
10/22 12:55:34 AM | NAME=cifar10-search
10/22 12:55:34 AM | NO_REPEAT=False
10/22 12:55:34 AM | PATH=searchs/cifar10-search
10/22 12:55:34 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:55:34 AM | PRETRAIN_DECAY=0
10/22 12:55:34 AM | PRETRAIN_EPOCHS=0
10/22 12:55:34 AM | PRINT_FREQ=10
10/22 12:55:34 AM | RETRAIN_EPOCHS=1
10/22 12:55:34 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:55:34 AM | RETRAIN_SETTING=0
10/22 12:55:34 AM | RETRAIN_UPDATE_W=True
10/22 12:55:34 AM | SAME_STRUCTURE=True
10/22 12:55:34 AM | SAMPLE_RATIO=0.2
10/22 12:55:34 AM | SEARCH_ITER=25
10/22 12:55:34 AM | SEARCH_ITER_EPOCHS=1
10/22 12:55:34 AM | SEED=0
10/22 12:55:34 AM | SHORT_CONNECT=False
10/22 12:55:34 AM | SYNC_PARAM=True
10/22 12:55:34 AM | TEACHER2STUDENT=True
10/22 12:55:34 AM | TEST_DIR=/data/imagenet/val
10/22 12:55:34 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:55:34 AM | TRAIN_MAIN_FIRST=False
10/22 12:55:34 AM | TRAIN_PORTION=0.5
10/22 12:55:34 AM | UNROLLED=False
10/22 12:55:34 AM | USE_BETA=True
10/22 12:55:34 AM | VAL_DIR=/data/imagenet/train
10/22 12:55:34 AM | W_GRAD_CLIP=5.0
10/22 12:55:34 AM | W_LR=0.05
10/22 12:55:34 AM | W_LR_MIN=0.001
10/22 12:55:34 AM | W_MOMENTUM=0.9
10/22 12:55:34 AM | W_WEIGHT_DECAY=0.0003
10/22 12:55:34 AM | WORKERS=1
10/22 12:55:34 AM | WORLD_SIZE=1
10/22 12:55:34 AM | 
10/22 12:55:34 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
Train: Layer 1/3 Epoch  1/25 Step 000/002 Loss 2.295 Prec@(1,5) (9.4%, 48.4%)
Train: Layer 1/3 Epoch  1/25 Step 001/002 Loss 2.302 Prec@(1,5) (10.9%, 47.7%)
Train: Layer 1/3 Epoch  1/25 Final Prec@1 10.9375%
Stage: 0 Layer: 1 genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Final best Prec@1 = 0.0000%
Stage: 0 Layer: 1 Best Genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Retrain Epoch 0 LR 0.05
10/22 12:57:28 AM | 
10/22 12:57:28 AM | Parameters:
10/22 12:57:28 AM | ALPHA_LR=0.0003
10/22 12:57:28 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:57:28 AM | AUX_WEIGHT=0.4
10/22 12:57:28 AM | BATCH_SIZE=64
10/22 12:57:28 AM | CELLS_NUM=3
10/22 12:57:28 AM | CLEAN_ARCH=True
10/22 12:57:28 AM | CUTOUT_LENGTH=16
10/22 12:57:28 AM | DATA_DIR=./cifar
10/22 12:57:28 AM | DATA_PATH=./data/
10/22 12:57:28 AM | DATASET=cifar10
10/22 12:57:28 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 12:57:28 AM | DISTRIBUTED=True
10/22 12:57:28 AM | DROP_PATH_PROB=0.2
10/22 12:57:28 AM | ENSEMBLE=True
10/22 12:57:28 AM | GPUS=[0]
10/22 12:57:28 AM | INIT_CHANNELS=16
10/22 12:57:28 AM | INPUT_CHANNELS=3
10/22 12:57:28 AM | LAYER_NUM=3
10/22 12:57:28 AM | LOCAL_RANK=0
10/22 12:57:28 AM | LR_RATIO=0.5
10/22 12:57:28 AM | MODEL_TYPE=cifar
10/22 12:57:28 AM | N_CLASSES=10
10/22 12:57:28 AM | NAME=cifar10-search
10/22 12:57:28 AM | NO_REPEAT=False
10/22 12:57:28 AM | PATH=searchs/cifar10-search
10/22 12:57:28 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:57:28 AM | PRETRAIN_DECAY=0
10/22 12:57:28 AM | PRETRAIN_EPOCHS=0
10/22 12:57:28 AM | PRINT_FREQ=10
10/22 12:57:28 AM | RETRAIN_EPOCHS=1
10/22 12:57:28 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:57:28 AM | RETRAIN_SETTING=0
10/22 12:57:28 AM | RETRAIN_UPDATE_W=True
10/22 12:57:28 AM | SAME_STRUCTURE=True
10/22 12:57:28 AM | SAMPLE_RATIO=0.2
10/22 12:57:28 AM | SEARCH_ITER=25
10/22 12:57:28 AM | SEARCH_ITER_EPOCHS=1
10/22 12:57:28 AM | SEED=0
10/22 12:57:28 AM | SHORT_CONNECT=False
10/22 12:57:28 AM | SYNC_PARAM=True
10/22 12:57:28 AM | TEACHER2STUDENT=True
10/22 12:57:28 AM | TEST_DIR=/data/imagenet/val
10/22 12:57:28 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:57:28 AM | TRAIN_MAIN_FIRST=False
10/22 12:57:28 AM | TRAIN_PORTION=0.5
10/22 12:57:28 AM | UNROLLED=False
10/22 12:57:28 AM | USE_BETA=True
10/22 12:57:28 AM | VAL_DIR=/data/imagenet/train
10/22 12:57:28 AM | W_GRAD_CLIP=5.0
10/22 12:57:28 AM | W_LR=0.05
10/22 12:57:28 AM | W_LR_MIN=0.001
10/22 12:57:28 AM | W_MOMENTUM=0.9
10/22 12:57:28 AM | W_WEIGHT_DECAY=0.0003
10/22 12:57:28 AM | WORKERS=1
10/22 12:57:28 AM | WORLD_SIZE=1
10/22 12:57:28 AM | 
10/22 12:57:28 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
Train: Layer 1/3 Epoch  1/25 Step 000/002 Loss 2.295 Prec@(1,5) (9.4%, 48.4%)
Train: Layer 1/3 Epoch  1/25 Step 001/002 Loss 2.302 Prec@(1,5) (10.9%, 47.7%)
Train: Layer 1/3 Epoch  1/25 Final Prec@1 10.9375%
Stage: 0 Layer: 1 genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Final best Prec@1 = 0.0000%
Stage: 0 Layer: 1 Best Genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Retrain Epoch 0 LR 0.05
10/22 12:58:12 AM | 
10/22 12:58:12 AM | Parameters:
10/22 12:58:12 AM | ALPHA_LR=0.0003
10/22 12:58:12 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:58:12 AM | AUX_WEIGHT=0.4
10/22 12:58:12 AM | BATCH_SIZE=64
10/22 12:58:12 AM | CELLS_NUM=3
10/22 12:58:12 AM | CLEAN_ARCH=True
10/22 12:58:12 AM | CUTOUT_LENGTH=16
10/22 12:58:12 AM | DATA_DIR=./cifar
10/22 12:58:12 AM | DATA_PATH=./data/
10/22 12:58:12 AM | DATASET=cifar10
10/22 12:58:12 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 12:58:12 AM | DISTRIBUTED=True
10/22 12:58:12 AM | DROP_PATH_PROB=0.2
10/22 12:58:12 AM | ENSEMBLE=True
10/22 12:58:12 AM | GPUS=[0]
10/22 12:58:12 AM | INIT_CHANNELS=16
10/22 12:58:12 AM | INPUT_CHANNELS=3
10/22 12:58:12 AM | LAYER_NUM=3
10/22 12:58:12 AM | LOCAL_RANK=0
10/22 12:58:12 AM | LR_RATIO=0.5
10/22 12:58:12 AM | MODEL_TYPE=cifar
10/22 12:58:12 AM | N_CLASSES=10
10/22 12:58:12 AM | NAME=cifar10-search
10/22 12:58:12 AM | NO_REPEAT=False
10/22 12:58:12 AM | PATH=searchs/cifar10-search
10/22 12:58:12 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:58:12 AM | PRETRAIN_DECAY=0
10/22 12:58:12 AM | PRETRAIN_EPOCHS=0
10/22 12:58:12 AM | PRINT_FREQ=10
10/22 12:58:12 AM | RETRAIN_EPOCHS=1
10/22 12:58:12 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:58:12 AM | RETRAIN_SETTING=0
10/22 12:58:12 AM | RETRAIN_UPDATE_W=True
10/22 12:58:12 AM | SAME_STRUCTURE=True
10/22 12:58:12 AM | SAMPLE_RATIO=0.2
10/22 12:58:12 AM | SEARCH_ITER=25
10/22 12:58:12 AM | SEARCH_ITER_EPOCHS=1
10/22 12:58:12 AM | SEED=0
10/22 12:58:12 AM | SHORT_CONNECT=False
10/22 12:58:12 AM | SYNC_PARAM=True
10/22 12:58:12 AM | TEACHER2STUDENT=True
10/22 12:58:12 AM | TEST_DIR=/data/imagenet/val
10/22 12:58:12 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:58:12 AM | TRAIN_MAIN_FIRST=False
10/22 12:58:12 AM | TRAIN_PORTION=0.5
10/22 12:58:12 AM | UNROLLED=False
10/22 12:58:12 AM | USE_BETA=True
10/22 12:58:12 AM | VAL_DIR=/data/imagenet/train
10/22 12:58:12 AM | W_GRAD_CLIP=5.0
10/22 12:58:12 AM | W_LR=0.05
10/22 12:58:12 AM | W_LR_MIN=0.001
10/22 12:58:12 AM | W_MOMENTUM=0.9
10/22 12:58:12 AM | W_WEIGHT_DECAY=0.0003
10/22 12:58:12 AM | WORKERS=1
10/22 12:58:12 AM | WORLD_SIZE=1
10/22 12:58:12 AM | 
10/22 12:58:12 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
Train: Layer 1/3 Epoch  1/25 Step 000/002 Loss 2.295 Prec@(1,5) (9.4%, 48.4%)
Train: Layer 1/3 Epoch  1/25 Step 001/002 Loss 2.302 Prec@(1,5) (10.9%, 47.7%)
Train: Layer 1/3 Epoch  1/25 Final Prec@1 10.9375%
Stage: 0 Layer: 1 genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Final best Prec@1 = 0.0000%
Stage: 0 Layer: 1 Best Genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Retrain Epoch 0 LR 0.05
10/22 12:59:06 AM | 
10/22 12:59:06 AM | Parameters:
10/22 12:59:06 AM | ALPHA_LR=0.0003
10/22 12:59:06 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 12:59:06 AM | AUX_WEIGHT=0.4
10/22 12:59:06 AM | BATCH_SIZE=64
10/22 12:59:06 AM | CELLS_NUM=3
10/22 12:59:06 AM | CLEAN_ARCH=True
10/22 12:59:06 AM | CUTOUT_LENGTH=16
10/22 12:59:06 AM | DATA_DIR=./cifar
10/22 12:59:06 AM | DATA_PATH=./data/
10/22 12:59:06 AM | DATASET=cifar10
10/22 12:59:06 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 12:59:06 AM | DISTRIBUTED=True
10/22 12:59:06 AM | DROP_PATH_PROB=0.2
10/22 12:59:06 AM | ENSEMBLE=True
10/22 12:59:06 AM | GPUS=[0]
10/22 12:59:06 AM | INIT_CHANNELS=16
10/22 12:59:06 AM | INPUT_CHANNELS=3
10/22 12:59:06 AM | LAYER_NUM=3
10/22 12:59:06 AM | LOCAL_RANK=0
10/22 12:59:06 AM | LR_RATIO=0.5
10/22 12:59:06 AM | MODEL_TYPE=cifar
10/22 12:59:06 AM | N_CLASSES=10
10/22 12:59:06 AM | NAME=cifar10-search
10/22 12:59:06 AM | NO_REPEAT=False
10/22 12:59:06 AM | PATH=searchs/cifar10-search
10/22 12:59:06 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 12:59:06 AM | PRETRAIN_DECAY=0
10/22 12:59:06 AM | PRETRAIN_EPOCHS=0
10/22 12:59:06 AM | PRINT_FREQ=10
10/22 12:59:06 AM | RETRAIN_EPOCHS=1
10/22 12:59:06 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 12:59:06 AM | RETRAIN_SETTING=0
10/22 12:59:06 AM | RETRAIN_UPDATE_W=True
10/22 12:59:06 AM | SAME_STRUCTURE=True
10/22 12:59:06 AM | SAMPLE_RATIO=0.2
10/22 12:59:06 AM | SEARCH_ITER=25
10/22 12:59:06 AM | SEARCH_ITER_EPOCHS=1
10/22 12:59:06 AM | SEED=0
10/22 12:59:06 AM | SHORT_CONNECT=False
10/22 12:59:06 AM | SYNC_PARAM=True
10/22 12:59:06 AM | TEACHER2STUDENT=True
10/22 12:59:06 AM | TEST_DIR=/data/imagenet/val
10/22 12:59:06 AM | TRAIN_DIR=/data/imagenet/train
10/22 12:59:06 AM | TRAIN_MAIN_FIRST=False
10/22 12:59:06 AM | TRAIN_PORTION=0.5
10/22 12:59:06 AM | UNROLLED=False
10/22 12:59:06 AM | USE_BETA=True
10/22 12:59:06 AM | VAL_DIR=/data/imagenet/train
10/22 12:59:06 AM | W_GRAD_CLIP=5.0
10/22 12:59:06 AM | W_LR=0.05
10/22 12:59:06 AM | W_LR_MIN=0.001
10/22 12:59:06 AM | W_MOMENTUM=0.9
10/22 12:59:06 AM | W_WEIGHT_DECAY=0.0003
10/22 12:59:06 AM | WORKERS=1
10/22 12:59:06 AM | WORLD_SIZE=1
10/22 12:59:06 AM | 
10/22 12:59:06 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
Train: Layer 1/3 Epoch  1/25 Step 000/002 Loss 2.295 Prec@(1,5) (9.4%, 48.4%)
Train: Layer 1/3 Epoch  1/25 Step 001/002 Loss 2.302 Prec@(1,5) (10.9%, 47.7%)
Train: Layer 1/3 Epoch  1/25 Final Prec@1 10.9375%
Stage: 0 Layer: 1 genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Final best Prec@1 = 0.0000%
Stage: 0 Layer: 1 Best Genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Retrain Epoch 0 LR 0.05
10/22 01:00:02 AM | 
10/22 01:00:02 AM | Parameters:
10/22 01:00:02 AM | ALPHA_LR=0.0003
10/22 01:00:02 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 01:00:02 AM | AUX_WEIGHT=0.4
10/22 01:00:02 AM | BATCH_SIZE=64
10/22 01:00:02 AM | CELLS_NUM=3
10/22 01:00:02 AM | CLEAN_ARCH=True
10/22 01:00:02 AM | CUTOUT_LENGTH=16
10/22 01:00:02 AM | DATA_DIR=./cifar
10/22 01:00:02 AM | DATA_PATH=./data/
10/22 01:00:02 AM | DATASET=cifar10
10/22 01:00:02 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 01:00:02 AM | DISTRIBUTED=True
10/22 01:00:02 AM | DROP_PATH_PROB=0.2
10/22 01:00:02 AM | ENSEMBLE=True
10/22 01:00:02 AM | GPUS=[0]
10/22 01:00:02 AM | INIT_CHANNELS=16
10/22 01:00:02 AM | INPUT_CHANNELS=3
10/22 01:00:02 AM | LAYER_NUM=3
10/22 01:00:02 AM | LOCAL_RANK=0
10/22 01:00:02 AM | LR_RATIO=0.5
10/22 01:00:02 AM | MODEL_TYPE=cifar
10/22 01:00:02 AM | N_CLASSES=10
10/22 01:00:02 AM | NAME=cifar10-search
10/22 01:00:02 AM | NO_REPEAT=False
10/22 01:00:02 AM | PATH=searchs/cifar10-search
10/22 01:00:02 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 01:00:02 AM | PRETRAIN_DECAY=0
10/22 01:00:02 AM | PRETRAIN_EPOCHS=0
10/22 01:00:02 AM | PRINT_FREQ=10
10/22 01:00:02 AM | RETRAIN_EPOCHS=1
10/22 01:00:02 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 01:00:02 AM | RETRAIN_SETTING=0
10/22 01:00:02 AM | RETRAIN_UPDATE_W=True
10/22 01:00:02 AM | SAME_STRUCTURE=True
10/22 01:00:02 AM | SAMPLE_RATIO=0.2
10/22 01:00:02 AM | SEARCH_ITER=25
10/22 01:00:02 AM | SEARCH_ITER_EPOCHS=1
10/22 01:00:02 AM | SEED=0
10/22 01:00:02 AM | SHORT_CONNECT=False
10/22 01:00:02 AM | SYNC_PARAM=True
10/22 01:00:02 AM | TEACHER2STUDENT=True
10/22 01:00:02 AM | TEST_DIR=/data/imagenet/val
10/22 01:00:02 AM | TRAIN_DIR=/data/imagenet/train
10/22 01:00:02 AM | TRAIN_MAIN_FIRST=False
10/22 01:00:02 AM | TRAIN_PORTION=0.5
10/22 01:00:02 AM | UNROLLED=False
10/22 01:00:02 AM | USE_BETA=True
10/22 01:00:02 AM | VAL_DIR=/data/imagenet/train
10/22 01:00:02 AM | W_GRAD_CLIP=5.0
10/22 01:00:02 AM | W_LR=0.05
10/22 01:00:02 AM | W_LR_MIN=0.001
10/22 01:00:02 AM | W_MOMENTUM=0.9
10/22 01:00:02 AM | W_WEIGHT_DECAY=0.0003
10/22 01:00:02 AM | WORKERS=1
10/22 01:00:02 AM | WORLD_SIZE=1
10/22 01:00:02 AM | 
10/22 01:00:02 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
Train: Layer 1/3 Epoch  1/25 Step 000/002 Loss 2.295 Prec@(1,5) (9.4%, 48.4%)
Train: Layer 1/3 Epoch  1/25 Step 001/002 Loss 2.302 Prec@(1,5) (10.9%, 47.7%)
Train: Layer 1/3 Epoch  1/25 Final Prec@1 10.9375%
Stage: 0 Layer: 1 genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Final best Prec@1 = 0.0000%
Stage: 0 Layer: 1 Best Genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Retrain Epoch 0 LR 0.05
Retrain: Layer 1/3 Epoch  1/25 Step 000/002 Loss 3.463 Loss_distill 1.154 Prec@(1,5) (9.4%, 48.4%)
Retrain: Layer 1/3 Epoch  1/25 Final Prec@1 10.1562%
10/22 01:01:30 AM | 
10/22 01:01:30 AM | Parameters:
10/22 01:01:30 AM | ALPHA_LR=0.0003
10/22 01:01:30 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 01:01:30 AM | AUX_WEIGHT=0.4
10/22 01:01:30 AM | BATCH_SIZE=64
10/22 01:01:30 AM | CELLS_NUM=3
10/22 01:01:30 AM | CLEAN_ARCH=True
10/22 01:01:30 AM | CUTOUT_LENGTH=16
10/22 01:01:30 AM | DATA_DIR=./cifar
10/22 01:01:30 AM | DATA_PATH=./data/
10/22 01:01:30 AM | DATASET=cifar10
10/22 01:01:30 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 01:01:30 AM | DISTRIBUTED=True
10/22 01:01:30 AM | DROP_PATH_PROB=0.2
10/22 01:01:30 AM | ENSEMBLE=True
10/22 01:01:30 AM | GPUS=[0]
10/22 01:01:30 AM | INIT_CHANNELS=16
10/22 01:01:30 AM | INPUT_CHANNELS=3
10/22 01:01:30 AM | LAYER_NUM=3
10/22 01:01:30 AM | LOCAL_RANK=0
10/22 01:01:30 AM | LR_RATIO=0.5
10/22 01:01:30 AM | MODEL_TYPE=cifar
10/22 01:01:30 AM | N_CLASSES=10
10/22 01:01:30 AM | NAME=cifar10-search
10/22 01:01:30 AM | NO_REPEAT=False
10/22 01:01:30 AM | PATH=searchs/cifar10-search
10/22 01:01:30 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 01:01:30 AM | PRETRAIN_DECAY=0
10/22 01:01:30 AM | PRETRAIN_EPOCHS=0
10/22 01:01:30 AM | PRINT_FREQ=10
10/22 01:01:30 AM | RETRAIN_EPOCHS=1
10/22 01:01:30 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 01:01:30 AM | RETRAIN_SETTING=0
10/22 01:01:30 AM | RETRAIN_UPDATE_W=True
10/22 01:01:30 AM | SAME_STRUCTURE=True
10/22 01:01:30 AM | SAMPLE_RATIO=0.2
10/22 01:01:30 AM | SEARCH_ITER=25
10/22 01:01:30 AM | SEARCH_ITER_EPOCHS=1
10/22 01:01:30 AM | SEED=0
10/22 01:01:30 AM | SHORT_CONNECT=False
10/22 01:01:30 AM | SYNC_PARAM=True
10/22 01:01:30 AM | TEACHER2STUDENT=True
10/22 01:01:30 AM | TEST_DIR=/data/imagenet/val
10/22 01:01:30 AM | TRAIN_DIR=/data/imagenet/train
10/22 01:01:30 AM | TRAIN_MAIN_FIRST=False
10/22 01:01:30 AM | TRAIN_PORTION=0.5
10/22 01:01:30 AM | UNROLLED=False
10/22 01:01:30 AM | USE_BETA=True
10/22 01:01:30 AM | VAL_DIR=/data/imagenet/train
10/22 01:01:30 AM | W_GRAD_CLIP=5.0
10/22 01:01:30 AM | W_LR=0.05
10/22 01:01:30 AM | W_LR_MIN=0.001
10/22 01:01:30 AM | W_MOMENTUM=0.9
10/22 01:01:30 AM | W_WEIGHT_DECAY=0.0003
10/22 01:01:30 AM | WORKERS=1
10/22 01:01:30 AM | WORLD_SIZE=1
10/22 01:01:30 AM | 
10/22 01:01:30 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
Train: Layer 1/3 Epoch  1/25 Step 000/002 Loss 2.295 Prec@(1,5) (9.4%, 48.4%)
Train: Layer 1/3 Epoch  1/25 Step 001/002 Loss 2.302 Prec@(1,5) (10.9%, 47.7%)
Train: Layer 1/3 Epoch  1/25 Final Prec@1 10.9375%
Stage: 0 Layer: 1 genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Final best Prec@1 = 0.0000%
Stage: 0 Layer: 1 Best Genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Retrain Epoch 0 LR 0.05
Retrain: Layer 1/3 Epoch  1/25 Step 000/002 Loss 3.463 Loss_distill 1.154 Prec@(1,5) (9.4%, 48.4%)
Retrain: Layer 1/3 Epoch  1/25 Final Prec@1 10.1562%
10/22 01:02:56 AM | 
10/22 01:02:56 AM | Parameters:
10/22 01:02:56 AM | ALPHA_LR=0.0003
10/22 01:02:56 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 01:02:56 AM | AUX_WEIGHT=0.4
10/22 01:02:56 AM | BATCH_SIZE=64
10/22 01:02:56 AM | CELLS_NUM=3
10/22 01:02:56 AM | CLEAN_ARCH=True
10/22 01:02:56 AM | CUTOUT_LENGTH=16
10/22 01:02:56 AM | DATA_DIR=./cifar
10/22 01:02:56 AM | DATA_PATH=./data/
10/22 01:02:56 AM | DATASET=cifar10
10/22 01:02:56 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 01:02:56 AM | DISTRIBUTED=True
10/22 01:02:56 AM | DROP_PATH_PROB=0.2
10/22 01:02:56 AM | ENSEMBLE=True
10/22 01:02:56 AM | GPUS=[0]
10/22 01:02:56 AM | INIT_CHANNELS=16
10/22 01:02:56 AM | INPUT_CHANNELS=3
10/22 01:02:56 AM | LAYER_NUM=3
10/22 01:02:56 AM | LOCAL_RANK=0
10/22 01:02:56 AM | LR_RATIO=0.5
10/22 01:02:56 AM | MODEL_TYPE=cifar
10/22 01:02:56 AM | N_CLASSES=10
10/22 01:02:56 AM | NAME=cifar10-search
10/22 01:02:56 AM | NO_REPEAT=False
10/22 01:02:56 AM | PATH=searchs/cifar10-search
10/22 01:02:56 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 01:02:56 AM | PRETRAIN_DECAY=0
10/22 01:02:56 AM | PRETRAIN_EPOCHS=0
10/22 01:02:56 AM | PRINT_FREQ=10
10/22 01:02:56 AM | RETRAIN_EPOCHS=1
10/22 01:02:56 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 01:02:56 AM | RETRAIN_SETTING=0
10/22 01:02:56 AM | RETRAIN_UPDATE_W=True
10/22 01:02:56 AM | SAME_STRUCTURE=True
10/22 01:02:56 AM | SAMPLE_RATIO=0.2
10/22 01:02:56 AM | SEARCH_ITER=25
10/22 01:02:56 AM | SEARCH_ITER_EPOCHS=1
10/22 01:02:56 AM | SEED=0
10/22 01:02:56 AM | SHORT_CONNECT=False
10/22 01:02:56 AM | SYNC_PARAM=True
10/22 01:02:56 AM | TEACHER2STUDENT=True
10/22 01:02:56 AM | TEST_DIR=/data/imagenet/val
10/22 01:02:56 AM | TRAIN_DIR=/data/imagenet/train
10/22 01:02:56 AM | TRAIN_MAIN_FIRST=False
10/22 01:02:56 AM | TRAIN_PORTION=0.5
10/22 01:02:56 AM | UNROLLED=False
10/22 01:02:56 AM | USE_BETA=True
10/22 01:02:56 AM | VAL_DIR=/data/imagenet/train
10/22 01:02:56 AM | W_GRAD_CLIP=5.0
10/22 01:02:56 AM | W_LR=0.05
10/22 01:02:56 AM | W_LR_MIN=0.001
10/22 01:02:56 AM | W_MOMENTUM=0.9
10/22 01:02:56 AM | W_WEIGHT_DECAY=0.0003
10/22 01:02:56 AM | WORKERS=1
10/22 01:02:56 AM | WORLD_SIZE=1
10/22 01:02:56 AM | 
10/22 01:02:56 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
Train: Layer 1/3 Epoch  1/25 Step 000/002 Loss 2.295 Prec@(1,5) (9.4%, 48.4%)
Train: Layer 1/3 Epoch  1/25 Step 001/002 Loss 2.302 Prec@(1,5) (10.9%, 47.7%)
Train: Layer 1/3 Epoch  1/25 Final Prec@1 10.9375%
Stage: 0 Layer: 1 genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Final best Prec@1 = 0.0000%
Stage: 0 Layer: 1 Best Genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Retrain Epoch 0 LR 0.05
Retrain: Layer 1/3 Epoch  1/25 Step 000/002 Loss 3.463 Loss_distill 1.154 Prec@(1,5) (9.4%, 48.4%)
Retrain: Layer 1/3 Epoch  1/25 Final Prec@1 10.1562%
10/22 01:03:57 AM | 
10/22 01:03:57 AM | Parameters:
10/22 01:03:57 AM | ALPHA_LR=0.0003
10/22 01:03:57 AM | ALPHA_WEIGHT_DECAY=0.001
10/22 01:03:57 AM | AUX_WEIGHT=0.4
10/22 01:03:57 AM | BATCH_SIZE=64
10/22 01:03:57 AM | CELLS_NUM=3
10/22 01:03:57 AM | CLEAN_ARCH=True
10/22 01:03:57 AM | CUTOUT_LENGTH=16
10/22 01:03:57 AM | DATA_DIR=./cifar
10/22 01:03:57 AM | DATA_PATH=./data/
10/22 01:03:57 AM | DATASET=cifar10
10/22 01:03:57 AM | DIST_URL=tcp://127.0.0.1:23343
10/22 01:03:57 AM | DISTRIBUTED=True
10/22 01:03:57 AM | DROP_PATH_PROB=0.2
10/22 01:03:57 AM | ENSEMBLE=True
10/22 01:03:57 AM | GPUS=[0]
10/22 01:03:57 AM | INIT_CHANNELS=16
10/22 01:03:57 AM | INPUT_CHANNELS=3
10/22 01:03:57 AM | LAYER_NUM=3
10/22 01:03:57 AM | LOCAL_RANK=0
10/22 01:03:57 AM | LR_RATIO=0.5
10/22 01:03:57 AM | MODEL_TYPE=cifar
10/22 01:03:57 AM | N_CLASSES=10
10/22 01:03:57 AM | NAME=cifar10-search
10/22 01:03:57 AM | NO_REPEAT=False
10/22 01:03:57 AM | PATH=searchs/cifar10-search
10/22 01:03:57 AM | PLOT_PATH=searchs/cifar10-search/plots
10/22 01:03:57 AM | PRETRAIN_DECAY=0
10/22 01:03:57 AM | PRETRAIN_EPOCHS=0
10/22 01:03:57 AM | PRINT_FREQ=10
10/22 01:03:57 AM | RETRAIN_EPOCHS=1
10/22 01:03:57 AM | RETRAIN_PATH=searchs/cifar10-search/retrains
10/22 01:03:57 AM | RETRAIN_SETTING=0
10/22 01:03:57 AM | RETRAIN_UPDATE_W=True
10/22 01:03:57 AM | SAME_STRUCTURE=True
10/22 01:03:57 AM | SAMPLE_RATIO=0.2
10/22 01:03:57 AM | SEARCH_ITER=25
10/22 01:03:57 AM | SEARCH_ITER_EPOCHS=1
10/22 01:03:57 AM | SEED=0
10/22 01:03:57 AM | SHORT_CONNECT=False
10/22 01:03:57 AM | SYNC_PARAM=True
10/22 01:03:57 AM | TEACHER2STUDENT=True
10/22 01:03:57 AM | TEST_DIR=/data/imagenet/val
10/22 01:03:57 AM | TRAIN_DIR=/data/imagenet/train
10/22 01:03:57 AM | TRAIN_MAIN_FIRST=False
10/22 01:03:57 AM | TRAIN_PORTION=0.5
10/22 01:03:57 AM | UNROLLED=False
10/22 01:03:57 AM | USE_BETA=True
10/22 01:03:57 AM | VAL_DIR=/data/imagenet/train
10/22 01:03:57 AM | W_GRAD_CLIP=5.0
10/22 01:03:57 AM | W_LR=0.05
10/22 01:03:57 AM | W_LR_MIN=0.001
10/22 01:03:57 AM | W_MOMENTUM=0.9
10/22 01:03:57 AM | W_WEIGHT_DECAY=0.0003
10/22 01:03:57 AM | WORKERS=1
10/22 01:03:57 AM | WORLD_SIZE=1
10/22 01:03:57 AM | 
10/22 01:03:57 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1248, 0.1254, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1251, 0.1247, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1251, 0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1251, 0.1250, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1251, 0.1252, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1252, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1252, 0.1250, 0.1248, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1249, 0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1252, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1248, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1250],
        [0.1251, 0.1249, 0.1248, 0.1248, 0.1251, 0.1252, 0.1249, 0.1251],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1252, 0.1250],
        [0.1252, 0.1251, 0.1248, 0.1250, 0.1248, 0.1249, 0.1252, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1252, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],
        [0.1248, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1252],
        [0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1248, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3330, 0.3332, 0.3338], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2503, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.1999, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3339, 0.3326, 0.3336], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2503, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2001, 0.2000, 0.1998, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250, 0.1248, 0.1248],
        [0.1250, 0.1251, 0.1249, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1250, 0.1250, 0.1253, 0.1252, 0.1247, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1249, 0.1252, 0.1249, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1248, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1252],
        [0.1250, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1250, 0.1250, 0.1247, 0.1250, 0.1250, 0.1249, 0.1252],
        [0.1248, 0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1249, 0.1250, 0.1253, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1251, 0.1248, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1250, 0.1248, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1251, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1252, 0.1251],
        [0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1251],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1250, 0.1250, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1248, 0.1249, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5007, 0.4993], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3337, 0.3329], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2498, 0.2500, 0.2499, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2001, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4997, 0.5003], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3331, 0.3335, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2499, 0.2498, 0.2503], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2001, 0.1999, 0.1998], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1250, 0.1252, 0.1250, 0.1248, 0.1249, 0.1250],
        [0.1248, 0.1249, 0.1249, 0.1252, 0.1249, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1250],
        [0.1252, 0.1250, 0.1248, 0.1252, 0.1249, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1251, 0.1249, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1248, 0.1249, 0.1249, 0.1251],
        [0.1248, 0.1250, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1251, 0.1249],
        [0.1251, 0.1248, 0.1252, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1251, 0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1248],
        [0.1248, 0.1250, 0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1250, 0.1252, 0.1251, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250],
        [0.1251, 0.1251, 0.1250, 0.1252, 0.1249, 0.1249, 0.1252, 0.1246]],
       device='cuda:0')
tensor([[0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1248, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1251, 0.1252, 0.1249, 0.1248, 0.1248, 0.1252],
        [0.1250, 0.1253, 0.1249, 0.1250, 0.1251, 0.1247, 0.1249, 0.1252]],
       device='cuda:0')
tensor([[0.1252, 0.1251, 0.1247, 0.1250, 0.1250, 0.1249, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1252, 0.1250, 0.1251],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250],
        [0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1253, 0.1250, 0.1251]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3335, 0.3330, 0.3335], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2503, 0.2498, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.1998, 0.1999, 0.2000, 0.2002], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0')
tensor([0.3336, 0.3333, 0.3331], device='cuda:0')
tensor([0.2502, 0.2503, 0.2498, 0.2498], device='cuda:0')
tensor([0.2001, 0.1999, 0.2003, 0.1999, 0.1997], device='cuda:0')
#####################
Train: Layer 1/3 Epoch  1/25 Step 000/002 Loss 2.295 Prec@(1,5) (9.4%, 48.4%)
Train: Layer 1/3 Epoch  1/25 Step 001/002 Loss 2.302 Prec@(1,5) (10.9%, 47.7%)
Train: Layer 1/3 Epoch  1/25 Final Prec@1 10.9375%
Stage: 0 Layer: 1 genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Final best Prec@1 = 0.0000%
Stage: 0 Layer: 1 Best Genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Retrain Epoch 0 LR 0.05
Retrain: Layer 1/3 Epoch  1/25 Step 000/002 Loss 3.463 Loss_distill 1.154 Prec@(1,5) (9.4%, 48.4%)
Retrain: Layer 1/3 Epoch  1/25 Final Prec@1 10.1562%
Valid: Layer 1/3 Epoch  1/25 Step 000/157 Loss 2.302 Prec@(1,5) (6.2%, 51.6%)
Valid: Layer 1/3 Epoch  1/25 Step 010/157 Loss 2.303 Prec@(1,5) (10.4%, 49.1%)
Valid: Layer 1/3 Epoch  1/25 Step 020/157 Loss 2.303 Prec@(1,5) (9.7%, 47.9%)
Valid: Layer 1/3 Epoch  1/25 Step 030/157 Loss 2.303 Prec@(1,5) (9.6%, 48.9%)
Valid: Layer 1/3 Epoch  1/25 Step 040/157 Loss 2.303 Prec@(1,5) (9.5%, 49.8%)
Valid: Layer 1/3 Epoch  1/25 Step 050/157 Loss 2.303 Prec@(1,5) (9.9%, 49.8%)
Valid: Layer 1/3 Epoch  1/25 Step 060/157 Loss 2.303 Prec@(1,5) (9.8%, 49.4%)
Valid: Layer 1/3 Epoch  1/25 Step 070/157 Loss 2.303 Prec@(1,5) (9.7%, 49.6%)
Valid: Layer 1/3 Epoch  1/25 Step 080/157 Loss 2.303 Prec@(1,5) (9.8%, 49.3%)
Valid: Layer 1/3 Epoch  1/25 Step 090/157 Loss 2.303 Prec@(1,5) (9.9%, 49.3%)
Valid: Layer 1/3 Epoch  1/25 Step 100/157 Loss 2.303 Prec@(1,5) (9.6%, 49.1%)
Valid: Layer 1/3 Epoch  1/25 Step 110/157 Loss 2.303 Prec@(1,5) (9.8%, 49.6%)
Valid: Layer 1/3 Epoch  1/25 Step 120/157 Loss 2.303 Prec@(1,5) (9.8%, 49.8%)
Valid: Layer 1/3 Epoch  1/25 Step 130/157 Loss 2.303 Prec@(1,5) (9.8%, 50.0%)
Valid: Layer 1/3 Epoch  1/25 Step 140/157 Loss 2.303 Prec@(1,5) (9.8%, 50.0%)
Valid: Layer 1/3 Epoch  1/25 Step 150/157 Loss 2.303 Prec@(1,5) (10.0%, 50.0%)
Valid: Layer 1/3 Epoch  1/25 Step 156/157 Loss 2.303 Prec@(1,5) (10.0%, 50.0%)
Valid: Layer 1/3 Epoch  1/25 Final Prec@1 10.0000%
Final best Prec@1 = 10.0000%
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3333, 0.3333], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2500, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3332, 0.3334, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2500, 0.2500, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2001], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.4999, 0.5001], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3333, 0.3333, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2499, 0.2501, 0.2500, 0.2501], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2000, 0.2000, 0.2001, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3333, 0.3334, 0.3333], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2500, 0.2500, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2001], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0')
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0')
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0')
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3333, 0.3334, 0.3333], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2500, 0.2499, 0.2501], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.2000, 0.2000, 0.2001], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0')
tensor([0.3333, 0.3333, 0.3333], device='cuda:0')
tensor([0.2500, 0.2500, 0.2500, 0.2500], device='cuda:0')
tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000], device='cuda:0')
#####################
Train: Layer 1/3 Epoch  2/25 Step 000/002 Loss 2.273 Prec@(1,5) (15.6%, 62.5%)
Train: Layer 1/3 Epoch  2/25 Step 001/002 Loss 2.264 Prec@(1,5) (18.0%, 57.8%)
Train: Layer 1/3 Epoch  2/25 Final Prec@1 17.9688%
Stage: 0 Layer: 1 genotype = Genotype(normal=[[('sep_conv_3x3', 1), ('sep_conv_5x5', 0)], [('sep_conv_5x5', 2), ('skip_connect', 1)], [('dil_conv_5x5', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 4), ('dil_conv_5x5', 0)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 1), ('max_pool_3x3', 2)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 0), ('dil_conv_3x3', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 genotype = Genotype(normal=[[('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 1), ('sep_conv_5x5', 0)], [('sep_conv_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_3x3', 3), ('avg_pool_3x3', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('max_pool_3x3', 0)], [('avg_pool_3x3', 2), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 4), ('max_pool_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('dil_conv_5x5', 0)], [('dil_conv_3x3', 3), ('sep_conv_5x5', 1)], [('dil_conv_5x5', 4), ('sep_conv_5x5', 0)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Final best Prec@1 = 10.0000%
Stage: 0 Layer: 1 Best Genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Retrain Epoch 1 LR 0.05
Retrain: Layer 1/3 Epoch  2/25 Step 000/002 Loss 3.433 Loss_distill 1.145 Prec@(1,5) (17.2%, 53.1%)
Retrain: Layer 1/3 Epoch  2/25 Final Prec@1 10.9375%
Valid: Layer 1/3 Epoch  2/25 Step 000/157 Loss 2.301 Prec@(1,5) (15.6%, 59.4%)
Valid: Layer 1/3 Epoch  2/25 Step 010/157 Loss 2.303 Prec@(1,5) (14.9%, 49.7%)
Valid: Layer 1/3 Epoch  2/25 Step 020/157 Loss 2.304 Prec@(1,5) (12.1%, 49.9%)
Valid: Layer 1/3 Epoch  2/25 Step 030/157 Loss 2.304 Prec@(1,5) (10.8%, 49.7%)
Valid: Layer 1/3 Epoch  2/25 Step 040/157 Loss 2.303 Prec@(1,5) (11.1%, 50.0%)
Valid: Layer 1/3 Epoch  2/25 Step 050/157 Loss 2.303 Prec@(1,5) (10.4%, 49.9%)
Valid: Layer 1/3 Epoch  2/25 Step 060/157 Loss 2.303 Prec@(1,5) (9.9%, 49.8%)
Valid: Layer 1/3 Epoch  2/25 Step 070/157 Loss 2.303 Prec@(1,5) (10.0%, 49.8%)
Valid: Layer 1/3 Epoch  2/25 Step 080/157 Loss 2.303 Prec@(1,5) (10.2%, 50.0%)
Valid: Layer 1/3 Epoch  2/25 Step 090/157 Loss 2.303 Prec@(1,5) (10.0%, 49.6%)
Valid: Layer 1/3 Epoch  2/25 Step 100/157 Loss 2.303 Prec@(1,5) (9.9%, 49.8%)
Valid: Layer 1/3 Epoch  2/25 Step 110/157 Loss 2.303 Prec@(1,5) (9.9%, 49.8%)
Valid: Layer 1/3 Epoch  2/25 Step 120/157 Loss 2.303 Prec@(1,5) (9.8%, 49.9%)
Valid: Layer 1/3 Epoch  2/25 Step 130/157 Loss 2.303 Prec@(1,5) (10.0%, 50.2%)
Valid: Layer 1/3 Epoch  2/25 Step 140/157 Loss 2.303 Prec@(1,5) (10.0%, 50.1%)
Valid: Layer 1/3 Epoch  2/25 Step 150/157 Loss 2.303 Prec@(1,5) (10.0%, 50.0%)
Valid: Layer 1/3 Epoch  2/25 Step 156/157 Loss 2.303 Prec@(1,5) (10.0%, 50.0%)
Valid: Layer 1/3 Epoch  2/25 Final Prec@1 10.0000%
Final best Prec@1 = 10.0000%
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.4999, 0.5001], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3332, 0.3334, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2500, 0.2500, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2000, 0.1999, 0.2000, 0.2001], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4999, 0.5001], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3333, 0.3334, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2501, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.2000, 0.2000, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3333, 0.3334, 0.3333], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2500, 0.2501], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3333, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2500, 0.2500, 0.2501], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.1999, 0.2000, 0.2000, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0')
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0')
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0')
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3333, 0.3335, 0.3333], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2500, 0.2499, 0.2501], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2000, 0.2000, 0.1999, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0')
tensor([0.3333, 0.3333, 0.3333], device='cuda:0')
tensor([0.2500, 0.2500, 0.2500, 0.2500], device='cuda:0')
tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000], device='cuda:0')
#####################
Train: Layer 1/3 Epoch  3/25 Step 000/002 Loss 2.251 Prec@(1,5) (18.8%, 68.8%)
Train: Layer 1/3 Epoch  3/25 Step 001/002 Loss 2.230 Prec@(1,5) (25.8%, 72.7%)
Train: Layer 1/3 Epoch  3/25 Final Prec@1 25.7812%
Stage: 0 Layer: 1 genotype = Genotype(normal=[[('skip_connect', 0), ('sep_conv_3x3', 1)], [('sep_conv_5x5', 2), ('avg_pool_3x3', 0)], [('dil_conv_5x5', 0), ('sep_conv_3x3', 2)], [('avg_pool_3x3', 0), ('dil_conv_3x3', 4)]], normal_concat=range(2, 6), reduce=[[('sep_conv_5x5', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 1), ('avg_pool_3x3', 2)], [('sep_conv_5x5', 1), ('dil_conv_5x5', 3)], [('dil_conv_3x3', 4), ('avg_pool_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 genotype = Genotype(normal=[[('sep_conv_3x3', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 0), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 1), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_5x5', 1)], [('dil_conv_3x3', 0), ('dil_conv_5x5', 1)], [('avg_pool_3x3', 3), ('dil_conv_5x5', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 genotype = Genotype(normal=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('sep_conv_5x5', 1), ('dil_conv_5x5', 0)], [('sep_conv_5x5', 3), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 4), ('sep_conv_5x5', 0)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Final best Prec@1 = 10.0000%
Stage: 0 Layer: 1 Best Genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Retrain Epoch 2 LR 0.05
Retrain: Layer 1/3 Epoch  3/25 Step 000/002 Loss 3.435 Loss_distill 1.145 Prec@(1,5) (10.9%, 67.2%)
Retrain: Layer 1/3 Epoch  3/25 Final Prec@1 7.8125%
Valid: Layer 1/3 Epoch  3/25 Step 000/157 Loss 2.303 Prec@(1,5) (10.9%, 45.3%)
Valid: Layer 1/3 Epoch  3/25 Step 010/157 Loss 2.301 Prec@(1,5) (10.4%, 52.4%)
Valid: Layer 1/3 Epoch  3/25 Step 020/157 Loss 2.303 Prec@(1,5) (9.2%, 51.9%)
Valid: Layer 1/3 Epoch  3/25 Step 030/157 Loss 2.303 Prec@(1,5) (9.3%, 51.0%)
Valid: Layer 1/3 Epoch  3/25 Step 040/157 Loss 2.304 Prec@(1,5) (9.1%, 50.3%)
Valid: Layer 1/3 Epoch  3/25 Step 050/157 Loss 2.303 Prec@(1,5) (9.1%, 50.3%)
Valid: Layer 1/3 Epoch  3/25 Step 060/157 Loss 2.304 Prec@(1,5) (9.5%, 50.3%)
Valid: Layer 1/3 Epoch  3/25 Step 070/157 Loss 2.303 Prec@(1,5) (9.7%, 50.3%)
Valid: Layer 1/3 Epoch  3/25 Step 080/157 Loss 2.303 Prec@(1,5) (9.7%, 50.3%)
Valid: Layer 1/3 Epoch  3/25 Step 090/157 Loss 2.303 Prec@(1,5) (9.4%, 50.1%)
Valid: Layer 1/3 Epoch  3/25 Step 100/157 Loss 2.303 Prec@(1,5) (9.6%, 50.4%)
Valid: Layer 1/3 Epoch  3/25 Step 110/157 Loss 2.303 Prec@(1,5) (9.9%, 50.6%)
Valid: Layer 1/3 Epoch  3/25 Step 120/157 Loss 2.303 Prec@(1,5) (10.0%, 50.4%)
Valid: Layer 1/3 Epoch  3/25 Step 130/157 Loss 2.303 Prec@(1,5) (10.1%, 50.2%)
Valid: Layer 1/3 Epoch  3/25 Step 140/157 Loss 2.303 Prec@(1,5) (10.0%, 50.0%)
Valid: Layer 1/3 Epoch  3/25 Step 150/157 Loss 2.303 Prec@(1,5) (10.0%, 50.1%)
Valid: Layer 1/3 Epoch  3/25 Step 156/157 Loss 2.303 Prec@(1,5) (10.0%, 50.0%)
Valid: Layer 1/3 Epoch  3/25 Final Prec@1 10.0000%
Final best Prec@1 = 10.0000%
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1251, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3332, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2500, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.2000, 0.2000, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.4999, 0.5001], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3333, 0.3334, 0.3333], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2500, 0.2499, 0.2501], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.4999, 0.5001], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3333, 0.3334, 0.3333], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2499, 0.2500, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2001, 0.2000, 0.2000, 0.1999], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3333, 0.3334, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2500, 0.2500, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2000, 0.1999, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0')
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0')
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0')
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3333, 0.3334, 0.3333], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2500, 0.2500, 0.2501], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.2000, 0.1999, 0.2001], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0')
tensor([0.3333, 0.3333, 0.3333], device='cuda:0')
tensor([0.2500, 0.2500, 0.2500, 0.2500], device='cuda:0')
tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000], device='cuda:0')
#####################
Train: Layer 1/3 Epoch  4/25 Step 000/002 Loss 2.214 Prec@(1,5) (26.6%, 68.8%)
Train: Layer 1/3 Epoch  4/25 Step 001/002 Loss 2.188 Prec@(1,5) (29.7%, 75.8%)
Train: Layer 1/3 Epoch  4/25 Final Prec@1 29.6875%
Stage: 0 Layer: 1 genotype = Genotype(normal=[[('sep_conv_3x3', 1), ('skip_connect', 0)], [('sep_conv_5x5', 2), ('sep_conv_5x5', 1)], [('sep_conv_3x3', 2), ('skip_connect', 1)], [('dil_conv_5x5', 2), ('sep_conv_5x5', 0)]], normal_concat=range(2, 6), reduce=[[('avg_pool_3x3', 1), ('max_pool_3x3', 0)], [('avg_pool_3x3', 1), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('avg_pool_3x3', 1), ('sep_conv_5x5', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 0), ('sep_conv_3x3', 3)], [('avg_pool_3x3', 1), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('avg_pool_3x3', 0), ('dil_conv_3x3', 1)], [('sep_conv_3x3', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('dil_conv_3x3', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 genotype = Genotype(normal=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 1), ('avg_pool_3x3', 2)], [('sep_conv_5x5', 3), ('avg_pool_3x3', 0)], [('avg_pool_3x3', 4), ('max_pool_3x3', 0)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Final best Prec@1 = 10.0000%
Stage: 0 Layer: 1 Best Genotype = Genotype(normal=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 2), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('avg_pool_3x3', 3), ('skip_connect', 4)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 0), ('dil_conv_3x3', 1)], [('dil_conv_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 0), ('sep_conv_5x5', 2)], [('dil_conv_5x5', 4), ('dil_conv_3x3', 2)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 2 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('dil_conv_5x5', 1)], [('sep_conv_5x5', 1), ('sep_conv_3x3', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 1)]], normal_concat=range(2, 6), reduce=[[('dil_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('avg_pool_3x3', 3), ('avg_pool_3x3', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 4)]], reduce_concat=range(2, 6))
Stage: 0 Layer: 3 Best Genotype = Genotype(normal=[[('sep_conv_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 2), ('dil_conv_3x3', 0)], [('sep_conv_5x5', 0), ('dil_conv_3x3', 3)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 4)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('avg_pool_3x3', 0), ('dil_conv_5x5', 1)], [('skip_connect', 1), ('dil_conv_3x3', 0)], [('avg_pool_3x3', 2), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
Retrain Epoch 3 LR 0.05
Retrain: Layer 1/3 Epoch  4/25 Step 000/002 Loss 3.459 Loss_distill 1.153 Prec@(1,5) (9.4%, 48.4%)
Retrain: Layer 1/3 Epoch  4/25 Final Prec@1 10.9375%
Valid: Layer 1/3 Epoch  4/25 Step 000/157 Loss 2.298 Prec@(1,5) (10.9%, 54.7%)
Valid: Layer 1/3 Epoch  4/25 Step 010/157 Loss 2.304 Prec@(1,5) (9.8%, 50.7%)
Valid: Layer 1/3 Epoch  4/25 Step 020/157 Loss 2.303 Prec@(1,5) (10.3%, 50.7%)
Valid: Layer 1/3 Epoch  4/25 Step 030/157 Loss 2.303 Prec@(1,5) (10.0%, 49.8%)
Valid: Layer 1/3 Epoch  4/25 Step 040/157 Loss 2.304 Prec@(1,5) (9.9%, 49.5%)
Valid: Layer 1/3 Epoch  4/25 Step 050/157 Loss 2.304 Prec@(1,5) (9.7%, 49.8%)
Valid: Layer 1/3 Epoch  4/25 Step 060/157 Loss 2.304 Prec@(1,5) (10.2%, 50.1%)
Valid: Layer 1/3 Epoch  4/25 Step 070/157 Loss 2.304 Prec@(1,5) (10.2%, 50.3%)
Valid: Layer 1/3 Epoch  4/25 Step 080/157 Loss 2.304 Prec@(1,5) (9.9%, 50.3%)
Valid: Layer 1/3 Epoch  4/25 Step 090/157 Loss 2.303 Prec@(1,5) (9.8%, 50.7%)
Valid: Layer 1/3 Epoch  4/25 Step 100/157 Loss 2.303 Prec@(1,5) (9.9%, 50.4%)
Valid: Layer 1/3 Epoch  4/25 Step 110/157 Loss 2.303 Prec@(1,5) (9.9%, 50.3%)
Valid: Layer 1/3 Epoch  4/25 Step 120/157 Loss 2.303 Prec@(1,5) (10.0%, 50.3%)
Valid: Layer 1/3 Epoch  4/25 Step 130/157 Loss 2.303 Prec@(1,5) (10.0%, 50.2%)
Valid: Layer 1/3 Epoch  4/25 Step 140/157 Loss 2.303 Prec@(1,5) (10.0%, 50.3%)
Valid: Layer 1/3 Epoch  4/25 Step 150/157 Loss 2.304 Prec@(1,5) (10.0%, 50.1%)
Valid: Layer 1/3 Epoch  4/25 Step 156/157 Loss 2.304 Prec@(1,5) (10.0%, 50.0%)
Valid: Layer 1/3 Epoch  4/25 Final Prec@1 10.0000%
Final best Prec@1 = 10.0000%
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3332, 0.3333, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2501, 0.2500, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3334, 0.3332], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2499, 0.2501, 0.2500, 0.2499], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
####### BETA #######
# Beta - normal
tensor([0.5000, 0.5000], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3333, 0.3334, 0.3333], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2501, 0.2500, 0.2500, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.1999, 0.2000, 0.2000, 0.2000, 0.2001], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5002, 0.4998], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3334, 0.3334, 0.3332], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2501, 0.2499, 0.2500], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2000, 0.2000, 0.2000, 0.1999, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
#####################
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0')
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0')
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0')
tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0')
#####################
####### BETA #######
# Beta - normal
tensor([0.5001, 0.4999], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.3333, 0.3334, 0.3333], device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([0.2500, 0.2500, 0.2499, 0.2501], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
tensor([0.2001, 0.2000, 0.2000, 0.2000, 0.2000], device='cuda:0',
       grad_fn=<SoftmaxBackward>)

# Beta - reduce
tensor([0.5000, 0.5000], device='cuda:0')
tensor([0.3333, 0.3333, 0.3333], device='cuda:0')
tensor([0.2500, 0.2500, 0.2500, 0.2500], device='cuda:0')
tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000], device='cuda:0')
#####################
